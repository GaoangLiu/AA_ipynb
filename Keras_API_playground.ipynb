{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_API_playground.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaH9Yqn7a2bevDCet1/ZR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaoangLiu/ipynb/blob/master/Keras_API_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ZPYxxI7os1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Input, layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rZv_ZW79Yia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "f91ed3e4-4b57-4f7c-97c0-b12c27c27117"
      },
      "source": [
        "class Kerasapi():\n",
        "    def __init__(self):\n",
        "        self.text_size = 10000\n",
        "        self.question_size = 10000\n",
        "        self.answer_size = 500\n",
        "    \n",
        "    def build_model(self):\n",
        "        text_input = Input(shape=(None, ), dtype='int32', name='text')\n",
        "        embedded_text = layers.Embedding(self.text_size, 64)(text_input)\n",
        "        encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "        question_input = Input(shape=(None, ), dtype=\"int32\", name='question')\n",
        "        embedded_question = layers.Embedding(self.question_size, 32)(question_input)\n",
        "        encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "        concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
        "        answer = layers.Dense(self.answer_size, activation='softmax')(concatenated)\n",
        "\n",
        "        model = Model([text_input, question_input], answer)\n",
        "        model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "        return model \n",
        "\n",
        "class I():\n",
        "    def fakedata(self):\n",
        "        num_samples = 1000\n",
        "        max_len = 100\n",
        "        dummy = Kerasapi()\n",
        "        text = np.random.randint(1, dummy.text_size, size=(num_samples, max_len))\n",
        "        question = np.random.randint(1, dummy.question_size, size=(num_samples, max_len))\n",
        "        answers = np.random.randint(dummy.answer_size, size=(num_samples))\n",
        "\n",
        "        answers = keras.utils.to_categorical(answers, dummy.answer_size)\n",
        "        return text, question, answers\n",
        "\n",
        "kapi = Kerasapi()\n",
        "model = kapi.build_model()\n",
        "i = I()\n",
        "t, q, a = i.fakedata()        \n",
        "model.fit([t, q], a, epochs=10, batch_size=128, verbose=1)\n",
        "# model.fit([t, q], a, epochs=10, batch_size=128)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.2147 - acc: 0.0040\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 6.2035 - acc: 0.0700\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 6.1906 - acc: 0.0940\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 6.1666 - acc: 0.0480\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 6.1029 - acc: 0.0090\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 6.0356 - acc: 0.0050\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 5.9754 - acc: 0.0070\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 5.9026 - acc: 0.0110\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 5.8139 - acc: 0.0190\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 5.7125 - acc: 0.0200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff9236ff860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq9RWq1VDGQS",
        "colab_type": "text"
      },
      "source": [
        "## A GRU template \n",
        "For processing Quora insincere questions classification ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuhrrgQiDNzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class C_GRU():\n",
        "    def __init__(self):\n",
        "        self.embed_size=300\n",
        "        self.max_features=50000\n",
        "        self.max_len=100\n",
        "    \n",
        "    def build_model(self):\n",
        "        text_input = Input(shape=(self.max_len, ))\n",
        "        embed_text = layers.Embedding(self.max_features, self.embed_size)(text_input)\n",
        "        \n",
        "        branch_a = layers.Bidirectional(layers.GRU(64, return_sequences=True))(embed_text)\n",
        "        branch_b = layers.GlobalMaxPool1D()(branch_a)\n",
        "        branch_c = layers.Dense(32, activation='relu')(branch_b)\n",
        "        branch_d = layers.Dropout(0.1)(branch_c)\n",
        "        branch_z = layers.Dense(1, activation='sigmoid')(branch_d)\n",
        "        \n",
        "        model = Model(inputs=text_input, outputs=branch_z)\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        \n",
        "        return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}