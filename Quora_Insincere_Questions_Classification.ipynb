{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora_Insincere_Questions_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPSxOfQUnww3YNFdn3En4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaoangLiu/ipynb/blob/master/Quora_Insincere_Questions_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3E1uAtsT17O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load packages \n",
        "import math\n",
        "import re\n",
        "import os\n",
        "import timeit\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import logging\n",
        "import time\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "logging.basicConfig(format='[%(asctime)s %(levelname)8s] %(message)s', level=logging.INFO, datefmt='%m-%d %H:%M:%S')\n",
        "\n",
        "# Get data\n",
        "! rm *.csv\n",
        "! wget -O quora.zip bwg.140714.xyz:8000/quora.zip \n",
        "! unzip quora.zip \n",
        "! ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bcd0v4GZiM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base class for classifier\n",
        "class Classifier():\n",
        "  def __init__(self):\n",
        "    self.train = None\n",
        "    self.test = None \n",
        "    self.model = None\n",
        "\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "  \n",
        "  def countvectorize(self):\n",
        "      tv = TfidfVectorizer(ngram_range=(1,3), token_pattern=r'\\w{1,}',\n",
        "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1, max_features=5000)\n",
        "      tv = CountVectorizer()\n",
        "      tv.fit(self.train.question_text)\n",
        "      self.vector_train = tv.transform(self.train.question_text)\n",
        "      self.vector_test  = tv.transform(self.test.question_text)\n",
        "      logging.info(\"Train & test text tokenized\")\n",
        "\n",
        "  def build_model(self):\n",
        "      pass\n",
        "\n",
        "  def run_model(self):\n",
        "      # Choose your own classifier: self.model and run it\n",
        "      logging.info(f\"{self.__class__.__name__} starts running.\")\n",
        "      labels = self.train.target\n",
        "      x_train, x_val, y_train, y_val = train_test_split(self.vector_train, labels, test_size=0.2, random_state=2090)\n",
        "      self.model.fit(x_train, y_train)\n",
        "      y_preds = self.model.predict(x_val)\n",
        "\n",
        "      logging.info(f\"Accuracy score: {accuracy_score(y_val, y_preds)}\")\n",
        "      logging.info(f\"Confusion matrix: \") \n",
        "      print(confusion_matrix(y_val, y_preds))\n",
        "      print(\"Classificaiton report:\\n\", classification_report(y_val, y_preds, target_names=[\"Sincere\", \"Insincere\"]))\n",
        "      # y_preds = self.model.predict(self.vector_test)\n",
        "      return y_preds\n",
        "\n",
        "  def save_predictions(self, y_preds):\n",
        "      sub = pd.read_csv(f\"sample_submission.csv\")\n",
        "      sub['prediction'] = y_preds \n",
        "      sub.to_csv(f\"submission_{self.__class__.__name__}.csv\", index=False)\n",
        "      logging.info('Prediction exported to submisison.csv')\n",
        "  \n",
        "  def pipeline(self):\n",
        "      s_time = time.clock()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "      self.build_model()\n",
        "      self.save_predictions(self.run_model())\n",
        "      logging.info(f\"Program running for {time.clock() - s_time} seconds\")\n",
        "\n",
        "class C_Bayes(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = MultinomialNB()\n",
        "      return self.model\n",
        "\n",
        "# Logistic Regression \n",
        "class C_LR(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = LogisticRegression(n_jobs=10, solver='lbfgs', C=0.1, verbose=1)\n",
        "      return self.model\n",
        "\n",
        "class C_SVM(Classifier):\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.train = self.train.sample(100000)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "\n",
        "  def build_model(self):\n",
        "      self.model = svm.SVC()\n",
        "      return self.model\n",
        "\n",
        "class C_Ensemble(Classifier):\n",
        "  def ensemble(self):\n",
        "      s_time = time.perf_counter()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "\n",
        "      nb = MultinomialNB()\n",
        "      lr = LogisticRegression(n_jobs=10, solver='saga', C=0.1, verbose=1)\n",
        "      svc = svm.SVC()\n",
        "\n",
        "      all_preds = [0] * self.test.shape[0]\n",
        "      for m in (nb, lr, svc):\n",
        "          self.model = m\n",
        "          if m == svc: \n",
        "              self.load_data()\n",
        "              self.train = self.train.sample(10000)\n",
        "              self.countvectorize()\n",
        "          all_preds += self.run_model()\n",
        "\n",
        "      all_preds = [1 if p > 0 else 0 for p in all_preds]\n",
        "      self.save_predictions(all_preds)\n",
        "      logging.info(f\"Program running for {time.perf_counter() - s_time} seconds\")\n",
        "\n",
        "\n",
        "class Helper():\n",
        "    def locate_threshold(self, model, x_val, y_val):\n",
        "        y_probs = model.predict_proba(x_val)\n",
        "        best_threshold = best_f1 = pre_f1 = 0\n",
        "        history = []\n",
        "\n",
        "        for i in range(0, 100):\n",
        "          y2_preds = [1 if e[1] >= i / 100 else 0 for e in y_probs]\n",
        "          cur_f1 = f1_score(y_val, y2_preds)\n",
        "          history.append((i, cur_f1))\n",
        "          symbol = '+' if cur_f1 >= pre_f1 else '-'\n",
        "          print(\"Threshold {:6.4f}, f1_score: {:<0.8f}  {} {:<0.6f} \".format(i / 100, cur_f1, symbol, abs(cur_f1 - pre_f1)))\n",
        "          pre_f1 = cur_f1\n",
        "\n",
        "          if cur_f1 >= best_f1:\n",
        "              best_f1 = cur_f1\n",
        "              best_threshold = i / 100\n",
        "\n",
        "        print(f\"Best f1 score {best_f1}, best threshold {best_threshold}\")\n",
        "        plt.xlabel('Threshold')\n",
        "        plt.ylabel('f1_score')\n",
        "        plt.plot(*zip(*history))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1mxAIjmVG_U",
        "colab_type": "text"
      },
      "source": [
        "## CNN\n",
        "We've tried linear models, the best result of private`f1_score` we got is 0.62166. Now we try Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAe8YZhVVFKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class C_NN(Classifier):\n",
        "    def build_model(self):\n",
        "        pass \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onAp-h_Ep8E6",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression \n",
        "Besides NB, we also tried LR to maximum `f1_score`\n",
        "\n",
        "2020.05.09: \n",
        "* Set `threshold = 0.21`, we got public score 0.60627 + private score = 0.62161. Bot are the maximum score we've got by now.\n",
        "<img class=\"center\" src=\"https://i.loli.net/2020/05/09/eE4KqloW52FDSdc.png\" alt=\"LR max f1_score\" width=850>\n",
        "* Set `threshold=0.25`, `public_score=0.60619` decreased, but `private_score=0.62166` increased. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4iCMLKZr68V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = C_LR()\n",
        "c.load_data()\n",
        "# b.train = b.train.sample(100000)\n",
        "c.countvectorize()\n",
        "labels = c.train.target\n",
        "x_train, x_val, y_train, y_val = train_test_split(c.vector_train, labels, test_size=0.2, random_state=2090)\n",
        "\n",
        "model = LogisticRegression(n_jobs=10, solver='saga', C=0.1, verbose=1)\n",
        "model.fit(x_train, y_train)\n",
        "y_preds = model.predict(x_val)\n",
        "\n",
        "print(f\"Accuracy score: {accuracy_score(y_val, y_preds)}\")\n",
        "print(f\"Confusion matrix: \") \n",
        "print(confusion_matrix(y_val, y_preds))\n",
        "print(\"Classificaiton report:\\n\", classification_report(y_val, y_preds, target_names=[\"Sincere\", \"Insincere\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBA9t30Hs4jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the best threshold to maximum f1_score\n",
        "Helper().locate_threshold(model, x_val, y_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b421RTCRhymn",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes\n",
        "Since in this contest submissions are evaluated on **F1 Score** between the predicted and the observed targets. Our ultimate goal is to maximum the `f1_socre`. \n",
        "\n",
        "2020.05.09: \n",
        "* Naive Bayes achieved the maximum score `f1_score = 0.56456695` when the `threshold` is set to `0.726`. This result in a public score = 0.56452 + private score = 0.56706. The public socre is the best we've got with NB, but the private score is only second to 0.56889, one when we set the `threshold` to 0.6 .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wchbncDhALOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = C_Bayes()\n",
        "b.load_data()\n",
        "b.countvectorize()\n",
        "b.build_model()\n",
        "labels = b.train.target\n",
        "x_train, x_val, y_train, y_val = train_test_split(b.vector_train, labels, test_size=0.2, random_state=2090)\n",
        "b.model.fit(x_train, y_train)\n",
        "y_preds = b.model.predict(x_val)\n",
        "\n",
        "logging.info(f\"Accuracy score: {accuracy_score(y_val, y_preds)}\")\n",
        "logging.info(f\"Confusion matrix: \") \n",
        "print(confusion_matrix(y_val, y_preds))\n",
        "print(\"Classificaiton report:\\n\", classification_report(y_val, y_preds, target_names=[\"Sincere\", \"Insincere\"]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_qcaj8UAsC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the best threshold to maximum f1_score\n",
        "Helper().locate_threshold(b.model, x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}