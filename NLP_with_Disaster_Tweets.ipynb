{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP with Disaster Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFqJNkKNEhZY47gv4v7ddv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaoangLiu/ipynb/blob/master/NLP_with_Disaster_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJNib6SIAGVa",
        "colab_type": "text"
      },
      "source": [
        "# NLP with Disaster Tweets\n",
        "\n",
        "Kaggle contest page: https://www.kaggle.com/c/nlp-getting-started/overview\n",
        "\n",
        "Task: predicts which Tweets are about real disasters and which one’s aren’t. Return value is either 1 (real) or 0 (unreal) .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q8SHrDH_8Pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4eeaccaa-4391-4689-dd8a-c5b2b32d06c7"
      },
      "source": [
        "# Load packages \n",
        "import math\n",
        "import re\n",
        "import os\n",
        "import timeit\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import logging\n",
        "import time\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "logging.basicConfig(format='[%(asctime)s %(levelname)8s] %(message)s', level=logging.INFO, datefmt='%m-%d %H:%M:%S')\n",
        "\n",
        "from keras import layers, Input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, LSTM, GRU, Bidirectional\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import gensim.downloader as api\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n",
            "[05-14 06:49:30     INFO] 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJLCawmzA1WS",
        "colab_type": "text"
      },
      "source": [
        "## Explore data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ldINPVLA5Yg",
        "colab_type": "code",
        "outputId": "a365baa0-7abf-414b-e3cb-55d1f07f8c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "! rm tweets.zip labels.csv \n",
        "! wget -O tweets.zip ali.140714.xyz:8000/nlp-getting-started.zip \n",
        "! unzip tweets.zip \n",
        "! ls\n",
        "! wget -O labels.csv ali.140714.xyz:8000/leaked_tweet_labels.csv\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'tweets.zip': No such file or directory\n",
            "rm: cannot remove 'labels.csv': No such file or directory\n",
            "--2020-05-14 06:49:42--  http://ali.140714.xyz:8000/nlp-getting-started.zip\n",
            "Resolving ali.140714.xyz (ali.140714.xyz)... 47.240.16.188\n",
            "Connecting to ali.140714.xyz (ali.140714.xyz)|47.240.16.188|:8000... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxzysppNBDne",
        "colab_type": "code",
        "outputId": "eb4ce515-7e83-47e1-e7e4-e1f82dfc0473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train.target.value_counts() \n",
        "\"\"\" \n",
        "0    4342\n",
        "1    3271\n",
        "Name: target, dtype: int64\n",
        "Good, so the data is WELL balanced\n",
        "\"\"\"\n",
        "train.keyword.value_counts()\n",
        "train.text.str.len().nsmallest(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1882     7\n",
              "4890     7\n",
              "5115     7\n",
              "24       8\n",
              "30       8\n",
              "3670     8\n",
              "4971     8\n",
              "28       9\n",
              "3667     9\n",
              "3749    10\n",
              "6705    10\n",
              "22      11\n",
              "4735    11\n",
              "5184    11\n",
              "6015    11\n",
              "784     12\n",
              "6522    12\n",
              "6917    12\n",
              "7470    12\n",
              "16      13\n",
              "2496    13\n",
              "3696    13\n",
              "15      14\n",
              "849     14\n",
              "6174    14\n",
              "6277    14\n",
              "7589    14\n",
              "900     15\n",
              "6224    15\n",
              "6258    15\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inq21zEjCoPF",
        "colab_type": "text"
      },
      "source": [
        "# CNN\n",
        "Dive into the data, build a baseline model with CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLxdiCYSCzEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base class for classifier\n",
        "class Classifier():\n",
        "  def __init__(self):\n",
        "    self.train = None\n",
        "    self.test = None \n",
        "    self.model = None\n",
        "\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "  \n",
        "  def countvectorize(self):\n",
        "      tv = TfidfVectorizer(ngram_range=(1,3), token_pattern=r'\\w{1,}',\n",
        "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1, max_features=5000)\n",
        "      tv = CountVectorizer()\n",
        "      tv.fit(self.train.text)\n",
        "      self.vector_train = tv.transform(self.train.text)\n",
        "      self.vector_test  = tv.transform(self.test.text)\n",
        "      logging.info(\"Train & test text tokenized\")\n",
        "\n",
        "  def build_model(self):\n",
        "      pass\n",
        "\n",
        "  def run_model(self):\n",
        "      # Choose your own classifier: self.model and run it\n",
        "      logging.info(f\"{self.__class__.__name__} starts running.\")\n",
        "      labels = self.train.target\n",
        "      x_train, x_val, y_train, y_val = train_test_split(self.vector_train, labels, test_size=0.2, random_state=20)\n",
        "      self.model.fit(x_train, y_train)\n",
        "      y_preds = self.model.predict(x_val)\n",
        "\n",
        "      logging.info(f\"Accuracy score: {accuracy_score(y_val, y_preds)}\")\n",
        "      logging.info(f\"Confusion matrix: \") \n",
        "      print(confusion_matrix(y_val, y_preds))\n",
        "      print(\"Classificaiton report:\\n\", classification_report(y_val, y_preds, target_names=[\"real\", \"unreal\"]))\n",
        "      y_preds = self.model.predict(self.vector_test)\n",
        "      return y_preds\n",
        "\n",
        "  def save_predictions(self, y_preds):\n",
        "      sub = pd.read_csv(f\"sample_submission.csv\")\n",
        "      sub['target'] = y_preds \n",
        "      sub.to_csv(f\"submission_{self.__class__.__name__}.csv\", index=False)\n",
        "      logging.info('Prediction exported to submisison.csv')\n",
        "  \n",
        "  def pipeline(self):\n",
        "      s_time = time.clock()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "      self.build_model()\n",
        "      self.save_predictions(self.run_model())\n",
        "      logging.info(f\"Program running for {time.clock() - s_time} seconds\")\n",
        "\n",
        "class C_Bayes(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = MultinomialNB()\n",
        "      return self.model\n",
        "\n",
        "# Logistic Regression \n",
        "class C_LR(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = LogisticRegression(n_jobs=10, solver='lbfgs', C=0.1, verbose=1)\n",
        "      return self.model\n",
        "\n",
        "class C_SVM(Classifier):\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "\n",
        "  def build_model(self):\n",
        "      self.model = svm.SVC()\n",
        "      return self.model\n",
        "\n",
        "class C_Ensemble(Classifier):\n",
        "  def ensemble(self):\n",
        "      s_time = time.perf_counter()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "\n",
        "      nb = MultinomialNB()\n",
        "      lr = LogisticRegression(n_jobs=10, solver='saga', C=0.1, verbose=1)\n",
        "      svc = svm.SVC()\n",
        "\n",
        "      all_preds = [0] * self.test.shape[0]\n",
        "      for m in (nb, lr, svc):\n",
        "          self.model = m\n",
        "          if m == svc: \n",
        "              self.load_data()\n",
        "              self.train = self.train.sample(10000)\n",
        "              self.countvectorize()\n",
        "          all_preds += self.run_model()\n",
        "\n",
        "      all_preds = [1 if p > 0 else 0 for p in all_preds]\n",
        "      self.save_predictions(all_preds)\n",
        "      logging.info(f\"Program running for {time.perf_counter() - s_time} seconds\")\n",
        "\n",
        "\n",
        "class Helper():\n",
        "    def locate_threshold(self, model, x_val, y_val):\n",
        "        y_probs = model.predict(x_val, batch_size=1024, verbose=1)\n",
        "        best_threshold = best_f1 = pre_f1 = 0\n",
        "        history = []\n",
        "\n",
        "        for i in np.arange(0.01, 1, 0.01):\n",
        "          if len(y_probs[0]) >= 2:\n",
        "              y2_preds = [1 if e[1] >= i else 0 for e in y_probs]\n",
        "          else:\n",
        "              y2_preds = (y_probs > i).astype(int)\n",
        "\n",
        "          cur_f1 = f1_score(y_val, y2_preds, average='weighted')\n",
        "          history.append((i, cur_f1))\n",
        "          symbol = '+' if cur_f1 >= pre_f1 else '-'\n",
        "          # print(\"Threshold {:6.4f}, f1_score: {:<0.8f}  {} {:<0.6f} \".format(i, cur_f1, symbol, abs(cur_f1 - pre_f1)))\n",
        "          pre_f1 = cur_f1\n",
        "\n",
        "          if cur_f1 >= best_f1:\n",
        "              best_f1 = cur_f1\n",
        "              best_threshold = i\n",
        "\n",
        "        print(f\"Best f1 score {best_f1}, best threshold {best_threshold}\")\n",
        "        plt.xlabel('Threshold')\n",
        "        plt.ylabel('f1_score')\n",
        "        plt.plot(*zip(*history))\n",
        "\n",
        "        return best_threshold\n",
        "\n",
        "class C_NN(Classifier):\n",
        "    def __init__(self, max_features=100000, embed_size=128, max_len=300):\n",
        "        self.max_features=max_features\n",
        "        self.embed_size=embed_size\n",
        "        self.max_len=max_len\n",
        "    \n",
        "    def tokenize_text(self, text_train, text_test):\n",
        "        '''@para: max_features, the most commenly used words in data set\n",
        "        @input are vector of text\n",
        "        '''\n",
        "        tokenizer = Tokenizer(num_words=self.max_features)\n",
        "        text = pd.concat([text_train, text_test])\n",
        "        tokenizer.fit_on_texts(text)\n",
        "\n",
        "        sequence_train = tokenizer.texts_to_sequences(text_train)\n",
        "        tokenized_train = pad_sequences(sequence_train, maxlen=self.max_len)\n",
        "        logging.info('Train text tokeninzed')\n",
        "\n",
        "        sequence_test = tokenizer.texts_to_sequences(text_test)\n",
        "        tokenized_test = pad_sequences(sequence_test, maxlen=self.max_len)\n",
        "        logging.info('Test text tokeninzed')\n",
        "        return tokenized_train, tokenized_test, tokenizer\n",
        "      \n",
        "    def build_model(self, embed_matrix=[]):\n",
        "        text_input = Input(shape=(self.max_len, ))\n",
        "        embed_text = layers.Embedding(self.max_features, self.embed_size)(text_input)\n",
        "        if len(embed_matrix) > 0:\n",
        "            embed_text = layers.Embedding(self.max_features, self.embed_size, \\\n",
        "                                          weights=[embed_matrix], trainable=False)(text_input)\n",
        "            \n",
        "        branch_a = layers.Bidirectional(layers.GRU(32, return_sequences=True))(embed_text)\n",
        "        branch_b = layers.GlobalMaxPool1D()(branch_a)\n",
        "\n",
        "        branch_c = layers.Dense(32, activation='relu')(branch_b)\n",
        "        branch_d = layers.Dropout(0.2)(branch_c)\n",
        "        branch_z = layers.Dense(1, activation='sigmoid')(branch_d)\n",
        "        \n",
        "        model = Model(inputs=text_input, outputs=branch_z)\n",
        "        self.model = model\n",
        "\n",
        "        return model\n",
        "        \n",
        "    def embed_word_vector(self, word_index, model='glove-wiki-gigaword-100'):\n",
        "        glove = api.load(model) # default: wikipedia 6B tokens, uncased\n",
        "        zeros = [0] * self.embed_size\n",
        "        matrix = np.zeros((self.max_features, self.embed_size))\n",
        "          \n",
        "        for word, i in word_index.items(): \n",
        "            if i >= self.max_features or word not in glove: continue # matrix[0] is zeros, that's also why >= is here\n",
        "            matrix[i] = glove[word]\n",
        "\n",
        "        logging.info('Matrix with embedded word vector created')\n",
        "        return matrix\n",
        "\n",
        "    def run(self, x_train, y_train):\n",
        "        checkpoint = ModelCheckpoint('weights_base_best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "        early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=3)\n",
        "\n",
        "        self.model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.8, random_state=2020)\n",
        "        BATCH_SIZE = max(16, 2 ** int(math.log(len(X_tra) / 100, 2)))\n",
        "        logging.info(f\"Batch size is set to {BATCH_SIZE}\")\n",
        "        history = self.model.fit(X_tra, y_tra, epochs=10, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), \\\n",
        "                              callbacks=[checkpoint, early], verbose=1)\n",
        "\n",
        "        return history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxV7G7YkcYeT",
        "colab_type": "text"
      },
      "source": [
        "## Now try linear models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM5RcKxhcagE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d40af570-f49a-4152-ba9d-6e6f3ce1a3d3"
      },
      "source": [
        "# c = C_Bayes()\n",
        "c = C_SVM()\n",
        "c.pipeline()\n",
        "labels = pd.read_csv('labels.csv').target\n",
        "preds = pd.read_csv('submission_C_SVM.csv').target\n",
        "print(\"The submission f1_score is: \", f1_score(labels, preds, average='weighted'))\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05-13 14:48:58     INFO] CSV data loaded\n",
            "[05-13 14:48:58     INFO] Train & test text tokenized\n",
            "[05-13 14:48:58     INFO] C_SVM starts running.\n",
            "[05-13 14:49:05     INFO] Accuracy score: 0.7918581746552856\n",
            "[05-13 14:49:05     INFO] Confusion matrix: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[799  77]\n",
            " [240 407]]\n",
            "Classificaiton report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        real       0.77      0.91      0.83       876\n",
            "      unreal       0.84      0.63      0.72       647\n",
            "\n",
            "    accuracy                           0.79      1523\n",
            "   macro avg       0.80      0.77      0.78      1523\n",
            "weighted avg       0.80      0.79      0.79      1523\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[05-13 14:49:08     INFO] Prediction exported to submisison.csv\n",
            "[05-13 14:49:08     INFO] Program running for 10.252798000001349 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The submission f1_score is:  0.7897567267823985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMYEiF3dDgsO",
        "colab_type": "text"
      },
      "source": [
        "Build a simple model and run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNhLSNSDksb",
        "colab_type": "code",
        "outputId": "24c74eac-baa7-496f-9b36-965615424cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "c = C_NN(max_features=10000, embed_size=100, max_len=150)\n",
        "c.load_data()\n",
        "vector_train, vector_test, tokenizer = c.tokenize_text(c.train.text, c.test.text)\n",
        "\n",
        "local_matrix = 'glove_twitter_100_matrix.npy'\n",
        "if os.path.exists(local_matrix):\n",
        "    matrix = np.load(local_matrix)\n",
        "    print(\"Load matrix from local file\")\n",
        "else:\n",
        "    matrix = c.embed_word_vector(tokenizer.word_index, 'glove-twitter-100')\n",
        "    np.save(local_matrix, matrix)\n",
        "    print(\"Save matrix to local file\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05-13 12:11:22     INFO] CSV data loaded\n",
            "[05-13 12:11:22     INFO] Train text tokeninzed\n",
            "[05-13 12:11:22     INFO] Test text tokeninzed\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load matrix from local file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awAEHBpsEQOR",
        "colab_type": "code",
        "outputId": "d76532eb-cd64-42d3-fa56-72f61d3a9f95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = c.build_model(matrix)\n",
        "c.run(vector_train, c.train.target)\n",
        "# X_tra, X_val, y_tra, y_val = train_test_split(vector_train, c.train.target, train_size=0.8, random_state=2020)\n",
        "# history = model.fit(X_tra, y_tra, epochs=3, batch_size=64, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05-13 12:11:27     INFO] Batch size is set to 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/10\n",
            "6090/6090 [==============================] - 114s 19ms/step - loss: 0.5384 - acc: 0.7335 - val_loss: 0.4476 - val_acc: 0.8017\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80171, saving model to weights_base_best.hdf5\n",
            "Epoch 2/10\n",
            "6090/6090 [==============================] - 112s 18ms/step - loss: 0.4386 - acc: 0.8049 - val_loss: 0.4503 - val_acc: 0.7951\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80171\n",
            "Epoch 3/10\n",
            "6090/6090 [==============================] - 111s 18ms/step - loss: 0.4107 - acc: 0.8223 - val_loss: 0.4512 - val_acc: 0.7971\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80171\n",
            "Epoch 4/10\n",
            "6090/6090 [==============================] - 108s 18ms/step - loss: 0.3897 - acc: 0.8322 - val_loss: 0.4286 - val_acc: 0.8102\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80171 to 0.81024, saving model to weights_base_best.hdf5\n",
            "Epoch 5/10\n",
            "6090/6090 [==============================] - 109s 18ms/step - loss: 0.3745 - acc: 0.8414 - val_loss: 0.4236 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.81024 to 0.81878, saving model to weights_base_best.hdf5\n",
            "Epoch 6/10\n",
            "6090/6090 [==============================] - 112s 18ms/step - loss: 0.3510 - acc: 0.8502 - val_loss: 0.4514 - val_acc: 0.7997\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.81878\n",
            "Epoch 7/10\n",
            "6090/6090 [==============================] - 111s 18ms/step - loss: 0.3337 - acc: 0.8588 - val_loss: 0.4268 - val_acc: 0.8214\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.81878 to 0.82141, saving model to weights_base_best.hdf5\n",
            "Epoch 8/10\n",
            "6090/6090 [==============================] - 112s 18ms/step - loss: 0.3183 - acc: 0.8700 - val_loss: 0.4389 - val_acc: 0.8227\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.82141 to 0.82272, saving model to weights_base_best.hdf5\n",
            "Epoch 9/10\n",
            "6090/6090 [==============================] - 112s 18ms/step - loss: 0.2975 - acc: 0.8811 - val_loss: 0.4542 - val_acc: 0.8004\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.82272\n",
            "Epoch 10/10\n",
            "6090/6090 [==============================] - 110s 18ms/step - loss: 0.2742 - acc: 0.8872 - val_loss: 0.4695 - val_acc: 0.8096\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.82272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff124978dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgatqwT1Foif",
        "colab_type": "code",
        "outputId": "8beeb9f2-650e-4e62-fae5-f255a6fcc587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# Find maximum threshold \n",
        "model = load_model('weights_base_best.hdf5')\n",
        "threshold = Helper().locate_threshold(model, X_val, y_val)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1523/1523 [==============================] - 0s 127us/step\n",
            "Best f1 score 0.8210686511812791, best threshold 0.42000000000000004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvo20EjjIDYr",
        "colab_type": "code",
        "outputId": "c9794d47-d794-42b2-8635-5b030386062d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# output submission\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "preds = model.predict(vector_test)\n",
        "\n",
        "if not threshold:\n",
        "    threshold = 0.3\n",
        "preds = (preds >= threshold).astype(int)\n",
        "sub.target = preds\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "\n",
        "labels = pd.read_csv('labels.csv').target\n",
        "print(\"The submission f1_score is: \", f1_score(labels, preds, average='weighted'))\n",
        "# submission result\n",
        "# GRU 64, max_features = 10000, embed_size=128, max_len=150, no embed, f1_score 0.75460\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Twitter 300, train_size 0.9 (default 0.8), f1_score 0.81083\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Google news 300, train_size 0.9 (default 0.8), f1_score 0.80195\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Google news 300, train_size 0.8 , f1_score 0.80826\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Glove wiki 300, train_size 0.8 , f1_score 0.81352\n",
        "# GRU 64, max_features = 10000, embed_size=100, max_len=150, Glove wiki 100, train_size 0.8 , f1_score 0.82004\n",
        "# Double GRU 64, max_features = 10000, embed_size=100, max_len=150, Glove wiki 100, train_size 0.8 , f1_score 0.81252\n",
        "\n",
        "# LSTM 64, max_features = 10000, embed_size=100, max_len=150, Glove wiki 100, train_size 0.8 , f1_score 0.81177\n",
        "# Double LSTM 64, max_features = 10000, embed_size=100, max_len=150, Glove wiki 100, train_size 0.8 , f1_score 0.80853\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The submission f1_score is:  0.8100469283697781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlFzsb2GLEJV",
        "colab_type": "code",
        "outputId": "b3fc2bd5-69a0-47c4-fac6-84c691507f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# upload to vps server\n",
        "!curl -X PUT --upload-file submission_C_SVM.csv ali.140714.xyz:8000/tweets.csv \n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 22746    0     0  100 22746      0  15184  0:00:01  0:00:01 --:--:-- 15174\n",
            "\n",
            "## Received: \"tweets.csv\"\n",
            "\n",
            "100 22775    0    29  100 22746     19  15184  0:00:01  0:00:01 --:--:-- 15193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcFTw-dGxfKg",
        "colab_type": "code",
        "outputId": "111a906c-1b12-4f4a-8298-288e3ad77cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Finally, wrap it up and upload zip file to vps server\n",
        "! rm nlp_disaster_tweets.zip \n",
        "! zip -r9 --exclude=sample_data/* nlp_disaster_tweets.zip *\n",
        "! curl -X PUT --upload-file nlp_disaster_tweets.zip ali.140714.xyz:8000\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: glove_twitter_100_matrix.csv (deflated 69%)\n",
            "  adding: glove_twitter_100_matrix.npy (deflated 59%)\n",
            "  adding: labels.csv (deflated 64%)\n",
            "  adding: sample_submission.csv (deflated 66%)\n",
            "  adding: submission.csv (deflated 65%)\n",
            "  adding: test.csv (deflated 56%)\n",
            "  adding: train.csv (deflated 59%)\n",
            "  adding: tweets.zip (deflated 0%)\n",
            "  adding: weights_base_best.hdf5 (deflated 26%)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            " 77 14.7M    0     0   77 11.5M      0  3198k  0:00:04  0:00:03  0:00:01 3198k\n",
            "\n",
            "## Received: \"nlp_disaster_tweets.zip\"\n",
            "\n",
            "100 14.7M    0    42  100 14.7M     10  3750k  0:00:04  0:00:04 --:--:-- 3750k\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}