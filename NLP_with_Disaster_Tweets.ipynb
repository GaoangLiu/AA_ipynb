{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP with Disaster Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsQUW+XXE2rn54laK05kb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaoangLiu/ipynb/blob/master/NLP_with_Disaster_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJNib6SIAGVa",
        "colab_type": "text"
      },
      "source": [
        "# NLP with Disaster Tweets\n",
        "\n",
        "Kaggle contest page: https://www.kaggle.com/c/nlp-getting-started/overview\n",
        "\n",
        "Task: predicts which Tweets are about real disasters and which one’s aren’t. Return value is either 1 (real) or 0 (unreal) .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q8SHrDH_8Pt",
        "colab_type": "code",
        "outputId": "489d97a6-6dcc-4b4a-d242-47238a32f006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Load packages \n",
        "import math\n",
        "import re\n",
        "import os\n",
        "import timeit\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import logging\n",
        "import time\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "logging.basicConfig(format='[%(asctime)s %(levelname)8s] %(message)s', level=logging.INFO, datefmt='%m-%d %H:%M:%S')\n",
        "\n",
        "from keras import layers, Input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, LSTM, GRU, Bidirectional\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import gensim.downloader as api\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n",
            "[05-13 06:48:47     INFO] 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJLCawmzA1WS",
        "colab_type": "text"
      },
      "source": [
        "## Explore data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ldINPVLA5Yg",
        "colab_type": "code",
        "outputId": "71457b20-ed2d-4ceb-d90a-27e5ffc03832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "! rm tweets.zip labels.csv \n",
        "！wget -O tweets.zip ali.140714.xyz:8000/nlp-getting-started.zip \n",
        "! unzip tweets.zip \n",
        "! ls\n",
        "! wget -O labels.csv ali.140714.xyz:8000/leaked_tweet_labels.csv\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-13 06:29:20--  http://ali.140714.xyz:8000/nlp-getting-started.zip\n",
            "Resolving ali.140714.xyz (ali.140714.xyz)... 47.240.16.188\n",
            "Connecting to ali.140714.xyz (ali.140714.xyz)|47.240.16.188|:8000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘tweets.zip’\n",
            "\n",
            "\rtweets.zip            0%[                    ]       0  --.-KB/s               \rtweets.zip            8%[>                   ]  49.01K   147KB/s               \rtweets.zip           32%[=====>              ] 195.47K   293KB/s               \rtweets.zip          100%[===================>] 593.11K   710KB/s    in 0.8s    \n",
            "\n",
            "2020-05-13 06:29:21 (710 KB/s) - ‘tweets.zip’ saved [607343/607343]\n",
            "\n",
            "Archive:  tweets.zip\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n",
            "labels.csv   sample_submission.csv  test.csv   tweets.zip\n",
            "sample_data  submission.csv\t    train.csv\n",
            "--2020-05-13 06:44:30--  http://ali.140714.xyz:8000/leaked_tweet_labels.csv\n",
            "Resolving ali.140714.xyz (ali.140714.xyz)... 47.240.16.188\n",
            "Connecting to ali.140714.xyz (ali.140714.xyz)|47.240.16.188|:8000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22746 (22K) [text/csv]\n",
            "Saving to: ‘labels.csv’\n",
            "\n",
            "labels.csv          100%[===================>]  22.21K   132KB/s    in 0.2s    \n",
            "\n",
            "2020-05-13 06:44:30 (132 KB/s) - ‘labels.csv’ saved [22746/22746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxzysppNBDne",
        "colab_type": "code",
        "outputId": "eb4ce515-7e83-47e1-e7e4-e1f82dfc0473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train.target.value_counts() \n",
        "\"\"\" \n",
        "0    4342\n",
        "1    3271\n",
        "Name: target, dtype: int64\n",
        "Good, so the data is WELL balanced\n",
        "\"\"\"\n",
        "train.keyword.value_counts()\n",
        "train.text.str.len().nsmallest(30)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1882     7\n",
              "4890     7\n",
              "5115     7\n",
              "24       8\n",
              "30       8\n",
              "3670     8\n",
              "4971     8\n",
              "28       9\n",
              "3667     9\n",
              "3749    10\n",
              "6705    10\n",
              "22      11\n",
              "4735    11\n",
              "5184    11\n",
              "6015    11\n",
              "784     12\n",
              "6522    12\n",
              "6917    12\n",
              "7470    12\n",
              "16      13\n",
              "2496    13\n",
              "3696    13\n",
              "15      14\n",
              "849     14\n",
              "6174    14\n",
              "6277    14\n",
              "7589    14\n",
              "900     15\n",
              "6224    15\n",
              "6258    15\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inq21zEjCoPF",
        "colab_type": "text"
      },
      "source": [
        "# CNN\n",
        "Dive into the data, build a baseline model with CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLxdiCYSCzEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base class for classifier\n",
        "class Classifier():\n",
        "  def __init__(self):\n",
        "    self.train = None\n",
        "    self.test = None \n",
        "    self.model = None\n",
        "\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "  \n",
        "  def countvectorize(self):\n",
        "      tv = TfidfVectorizer(ngram_range=(1,3), token_pattern=r'\\w{1,}',\n",
        "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1, max_features=5000)\n",
        "      tv = CountVectorizer()\n",
        "      tv.fit(self.train.question_text)\n",
        "      self.vector_train = tv.transform(self.train.question_text)\n",
        "      self.vector_test  = tv.transform(self.test.question_text)\n",
        "      logging.info(\"Train & test text tokenized\")\n",
        "\n",
        "  def build_model(self):\n",
        "      pass\n",
        "\n",
        "  def run_model(self):\n",
        "      # Choose your own classifier: self.model and run it\n",
        "      logging.info(f\"{self.__class__.__name__} starts running.\")\n",
        "      labels = self.train.target\n",
        "      x_train, x_val, y_train, y_val = train_test_split(self.vector_train, labels, test_size=0.2, random_state=2090)\n",
        "      self.model.fit(x_train, y_train)\n",
        "      y_preds = self.model.predict(x_val)\n",
        "\n",
        "      logging.info(f\"Accuracy score: {accuracy_score(y_val, y_preds)}\")\n",
        "      logging.info(f\"Confusion matrix: \") \n",
        "      print(confusion_matrix(y_val, y_preds))\n",
        "      print(\"Classificaiton report:\\n\", classification_report(y_val, y_preds, target_names=[\"Sincere\", \"Insincere\"]))\n",
        "      # y_preds = self.model.predict(self.vector_test)\n",
        "      return y_preds\n",
        "\n",
        "  def save_predictions(self, y_preds):\n",
        "      sub = pd.read_csv(f\"sample_submission.csv\")\n",
        "      sub['prediction'] = y_preds \n",
        "      sub.to_csv(f\"submission_{self.__class__.__name__}.csv\", index=False)\n",
        "      logging.info('Prediction exported to submisison.csv')\n",
        "  \n",
        "  def pipeline(self):\n",
        "      s_time = time.clock()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "      self.build_model()\n",
        "      self.save_predictions(self.run_model())\n",
        "      logging.info(f\"Program running for {time.clock() - s_time} seconds\")\n",
        "\n",
        "class C_Bayes(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = MultinomialNB()\n",
        "      return self.model\n",
        "\n",
        "# Logistic Regression \n",
        "class C_LR(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = LogisticRegression(n_jobs=10, solver='lbfgs', C=0.1, verbose=1)\n",
        "      return self.model\n",
        "\n",
        "class C_SVM(Classifier):\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.train = self.train.sample(100000)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "\n",
        "  def build_model(self):\n",
        "      self.model = svm.SVC()\n",
        "      return self.model\n",
        "\n",
        "class C_Ensemble(Classifier):\n",
        "  def ensemble(self):\n",
        "      s_time = time.perf_counter()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "\n",
        "      nb = MultinomialNB()\n",
        "      lr = LogisticRegression(n_jobs=10, solver='saga', C=0.1, verbose=1)\n",
        "      svc = svm.SVC()\n",
        "\n",
        "      all_preds = [0] * self.test.shape[0]\n",
        "      for m in (nb, lr, svc):\n",
        "          self.model = m\n",
        "          if m == svc: \n",
        "              self.load_data()\n",
        "              self.train = self.train.sample(10000)\n",
        "              self.countvectorize()\n",
        "          all_preds += self.run_model()\n",
        "\n",
        "      all_preds = [1 if p > 0 else 0 for p in all_preds]\n",
        "      self.save_predictions(all_preds)\n",
        "      logging.info(f\"Program running for {time.perf_counter() - s_time} seconds\")\n",
        "\n",
        "\n",
        "class Helper():\n",
        "    def locate_threshold(self, model, x_val, y_val):\n",
        "        y_probs = model.predict(x_val, batch_size=1024, verbose=1)\n",
        "        best_threshold = best_f1 = pre_f1 = 0\n",
        "        history = []\n",
        "\n",
        "        for i in np.arange(0.01, 1, 0.01):\n",
        "          if len(y_probs[0]) >= 2:\n",
        "              y2_preds = [1 if e[1] >= i else 0 for e in y_probs]\n",
        "          else:\n",
        "              y2_preds = (y_probs > i).astype(int)\n",
        "\n",
        "          cur_f1 = f1_score(y_val, y2_preds, average='weighted')\n",
        "          history.append((i, cur_f1))\n",
        "          symbol = '+' if cur_f1 >= pre_f1 else '-'\n",
        "          # print(\"Threshold {:6.4f}, f1_score: {:<0.8f}  {} {:<0.6f} \".format(i, cur_f1, symbol, abs(cur_f1 - pre_f1)))\n",
        "          pre_f1 = cur_f1\n",
        "\n",
        "          if cur_f1 >= best_f1:\n",
        "              best_f1 = cur_f1\n",
        "              best_threshold = i\n",
        "\n",
        "        print(f\"Best f1 score {best_f1}, best threshold {best_threshold}\")\n",
        "        plt.xlabel('Threshold')\n",
        "        plt.ylabel('f1_score')\n",
        "        plt.plot(*zip(*history))\n",
        "\n",
        "        return best_threshold\n",
        "\n",
        "class C_NN(Classifier):\n",
        "    def __init__(self, max_features=100000, embed_size=128, max_len=300):\n",
        "        self.max_features=max_features\n",
        "        self.embed_size=embed_size\n",
        "        self.max_len=max_len\n",
        "    \n",
        "    def tokenize_text(self, text_train, text_test):\n",
        "        '''@para: max_features, the most commenly used words in data set\n",
        "        @input are vector of text\n",
        "        '''\n",
        "        tokenizer = Tokenizer(num_words=self.max_features)\n",
        "        text = pd.concat([text_train, text_test])\n",
        "        tokenizer.fit_on_texts(text)\n",
        "\n",
        "        sequence_train = tokenizer.texts_to_sequences(text_train)\n",
        "        tokenized_train = pad_sequences(sequence_train, maxlen=self.max_len)\n",
        "        logging.info('Train text tokeninzed')\n",
        "\n",
        "        sequence_test = tokenizer.texts_to_sequences(text_test)\n",
        "        tokenized_test = pad_sequences(sequence_test, maxlen=self.max_len)\n",
        "        logging.info('Test text tokeninzed')\n",
        "        return tokenized_train, tokenized_test, tokenizer\n",
        "      \n",
        "    def build_model(self, embed_matrix=[]):\n",
        "        text_input = Input(shape=(self.max_len, ))\n",
        "        embed_text = layers.Embedding(self.max_features, self.embed_size)(text_input)\n",
        "        if len(embed_matrix) > 0:\n",
        "            embed_text = layers.Embedding(self.max_features, self.embed_size, \\\n",
        "                                          weights=[embed_matrix], trainable=False)(text_input)\n",
        "            \n",
        "\n",
        "        branch_a = layers.Bidirectional(layers.GRU(64, return_sequences=True))(embed_text)\n",
        "        branch_b = layers.GlobalMaxPool1D()(branch_a)\n",
        "\n",
        "        branch_c = layers.Dense(64, activation='relu')(branch_b)\n",
        "        branch_d = layers.Dropout(0.2)(branch_c)\n",
        "        branch_c = layers.Dense(64, activation='relu')(branch_b)\n",
        "        branch_d = layers.Dropout(0.2)(branch_c)\n",
        "        branch_z = layers.Dense(1, activation='sigmoid')(branch_d)\n",
        "        \n",
        "        model = Model(inputs=text_input, outputs=branch_z)\n",
        "        self.model = model\n",
        "\n",
        "        return model\n",
        "        \n",
        "    def embed_word_vector(self, word_index, model='glove-wiki-gigaword-100'):\n",
        "        glove = api.load(model) # default: wikipedia 6B tokens, uncased\n",
        "        zeros = [0] * self.embed_size\n",
        "        matrix = np.zeros((self.max_features, self.embed_size))\n",
        "          \n",
        "        for word, i in word_index.items(): \n",
        "            if i >= self.max_features or word not in glove: continue # matrix[0] is zeros, that's also why >= is here\n",
        "            matrix[i] = glove[word]\n",
        "\n",
        "        logging.info('Matrix with embedded word vector created')\n",
        "        return matrix\n",
        "\n",
        "    def run(self, x_train, y_train):\n",
        "        checkpoint = ModelCheckpoint('weights_base_best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "        early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=3)\n",
        "\n",
        "        self.model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.8, random_state=2020)\n",
        "        BATCH_SIZE = max(16, 2 ** int(math.log(len(X_tra) / 100, 2)))\n",
        "        logging.info(f\"Batch size is set to {BATCH_SIZE}\")\n",
        "        history = self.model.fit(X_tra, y_tra, epochs=10, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), \\\n",
        "                              callbacks=[checkpoint, early], verbose=1)\n",
        "\n",
        "        y_pred = self.model.predict(X_val, batch_size=64, verbose=1)\n",
        "        y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "        print(classification_report(y_val, y_pred_bool))\n",
        "        return history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMYEiF3dDgsO",
        "colab_type": "text"
      },
      "source": [
        "Build a simple model and run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNhLSNSDksb",
        "colab_type": "code",
        "outputId": "38855c1d-3f16-479b-89da-932274d71284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "c = C_NN(max_features=10000, embed_size=300, max_len=150)\n",
        "c.load_data()\n",
        "vector_train, vector_test, tokenizer = c.tokenize_text(c.train.text, c.test.text)\n",
        "\n",
        "matrix = c.embed_word_vector(tokenizer.word_index, 'glove-wiki-gigaword-300')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05-13 09:06:11     INFO] CSV data loaded\n",
            "[05-13 09:06:12     INFO] Train text tokeninzed\n",
            "[05-13 09:06:12     INFO] Test text tokeninzed\n",
            "[05-13 09:06:12     INFO] loading projection weights from /root/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "[05-13 09:07:55     INFO] loaded (400000, 300) matrix from /root/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
            "[05-13 09:07:55     INFO] Matrix with embedded word vector created\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiEjgqniNbjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awAEHBpsEQOR",
        "colab_type": "code",
        "outputId": "79bd78d1-ac8c-4fcf-f328-40d2c59ca489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "model = c.build_model(matrix)\n",
        "c.run(vector_train, c.train.target)\n",
        "# X_tra, X_val, y_tra, y_val = train_test_split(vector_train, c.train.target, train_size=0.8, random_state=2020)\n",
        "# history = model.fit(X_tra, y_tra, epochs=3, batch_size=64, validation_data=(X_val, y_val))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05-13 09:08:44     INFO] Batch size is set to 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/2\n",
            "6090/6090 [==============================] - 114s 19ms/step - loss: 0.4848 - acc: 0.7747 - val_loss: 0.4943 - val_acc: 0.7840\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78398, saving model to weights_base_best.hdf5\n",
            "Epoch 2/2\n",
            "6090/6090 [==============================] - 109s 18ms/step - loss: 0.4011 - acc: 0.8307 - val_loss: 0.4306 - val_acc: 0.8142\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78398 to 0.81418, saving model to weights_base_best.hdf5\n",
            "1523/1523 [==============================] - 1s 793us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.72       849\n",
            "           1       0.00      0.00      0.00       674\n",
            "\n",
            "    accuracy                           0.56      1523\n",
            "   macro avg       0.28      0.50      0.36      1523\n",
            "weighted avg       0.31      0.56      0.40      1523\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff131fec828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgatqwT1Foif",
        "colab_type": "code",
        "outputId": "85e9bd4d-f549-4091-ab60-10c2a978ea58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# Find maximum threshold \n",
        "model = \n",
        "threshold = Helper().locate_threshold(model, X_val, y_val)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1523/1523 [==============================] - 0s 119us/step\n",
            "Best f1 score 0.8208978370547855, best threshold 0.46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxV9Z3/8dcnO1kIZGVPwg4iguA61r0W24621aloO3Ydp51a7bR1xv7m12XszPy6/KbtOOO01Y6j0/7qVqsyI1Vbd8UFkCACAiEESFgSCEnIvn1+f9yLjchyCTn3JPe+n49HHtx77sm5nxPgvvNdzveYuyMiIskrJewCREQkXAoCEZEkpyAQEUlyCgIRkSSnIBARSXJpYRcwGEVFRV5eXh52GSIiI8rq1av3uXvx4dtHZBCUl5ezatWqsMsQERlRzGz7kbara0hEJMkpCEREkpyCQEQkySkIRESSnIJARCTJKQhERJKcgkBEJMmNyOsIRILU0d3Hht3NvFnbTHNHD+mpKWSmpZCRlkJWWiqZ6SmMzx/ForKxpKZY2OWKnDQFgSS9zp4+VtY08tKWfbxUtY+39xykr//49+koycvkw/Mn8P65pUwpzKYkL5P0VDWyZeRREEhCau7oYUXVPl7b1siOxna2729jb0sXo7PSKB6dRUF2Ogfae9jd3EH9wS7cIT3VWFQ2lr+6cBrzJ41h/qR8inIz6enrp6evn67efjp7+ujq7Wfj7haWVe7iV69u5+6XtwFgBhPyR3HW1ALOm17EGeUF9PT109TRQ3tXH6eXjSE7Q//lZPixkXiHssWLF7uWmEhe/f3O7pZOqupb2bi7hY27W9jd3ElGagrpqUZLZy+VO5vo63eyM1IpL8xhSkE24/KzaOnsoeFgF41t3YzNzmDCmCzG549iwZQxnFVRcMIf1M0dPazZcYA9zZ3sau5ka0Mrr2zdT2Nb93v2HZ2VxrVnTeFT55STm5XGjv3t1B5op6fPyUxLISs9ldnj8yjJyxqqH5XIu5jZandf/J7tCgIJi7vzZm0z/712F0+/XU+KQXFeJsV5WRTnZlKcl0lRbgbt3X3U7G9j+/52ava3UdvYQXdf/zvHmZCfxaSCbPr6nZ6+ftJTUzhnaiEXzCpmweQxce+u6e93NuxuYW1tE9kZqYzJzgCHh1bv5Im39nCsXqe0FGPJvHF86txyFpeNxUxjEDJ0FAQSmr5+f9egak9fPw+vruVnz2+lZn876anGn0wvIjsjlYaDXe98tXX3vfM92RmplBXmUF6YzZTCbMoKcqgoymHO+LzIB+0IUXugnUfeqCM9LYWygmwmF2STmZZCV28/bV29PLVhLw+t2klLZy+zx+XxqXPLuXLBBHUpyZAILQjMbAnwL0Aq8At3/95hr08B7gXGRPe51d2XH+uYCoLh7YXNDTz8Ri01+yN98wc7e5k3MZ+zKwooHZ3Ff67Yxs7GDk6blM8nzirjA6eMIz87/T3HaevqpeFgF9kZqRTnZSbNb8ft3b08VrmLe1fU8Paeg4zOSuODp45nzvjRzCjNZe740SMq/GT4CCUIzCwV2Ay8H6gFVgLXuvuGAfvcCaxx95+a2VxgubuXH+u4CoLhaWdjO9/9nw08tWEvRbmZzBmfR1lhNjmZabyx/QCVO5vo6XNOnZjPX79/BhfNKkmaD/fBcHdW1hzg3ldqeHFzAy2dvQCkphjnTS/iygUTuOyUceRmqrUgsTlaEAT9L+hMoMrdq6NF3A9cCWwYsI8Do6OP84FdAdckQ6i1q5eXtuzj2bfrebSyjhQz/mbJLD53XgWZaanv2reju4/aA+1ML8lVAMTAzDizooAzKwpwd+oPdrF570FWbN3PsspdfPXBtcBaCnIyKMnLZNLYUVx2yjgunzeOvKz3trBEjiboFsHVwBJ3/3z0+Z8DZ7n7jQP2GQ88BYwFcoBL3X31EY51A3ADwJQpUxZt337E+ytIgHr7+vnFS9tYua2R5o4emjt6qNnfRk+fk5eZxmWnjONrl81kwphRYZea8NydN3Yc4KUt+9l7sJP6lkhI7GhsJys9hcvmjuOSOSWcN72IwtzMsMuVYSKsFkEsrgXucfd/NrNzgF+a2Tx37x+4k7vfCdwJka6hEOpManuaO7np/jW8vq2RmaW5FOZkMr0kl4vnlHDRrBIWlY3VxVRxZGYsKitgUVnBO9vcnTU7m/jtG7X8z5u7WbY20rieM3404/OzGJWRSnZ6KqdMGM1Fs0soK8wJq3wZZoJuEZwDfMfdPxB9/g0Ad/8/A/ZZT6TVsDP6vBo4293rj3ZcjREEr7mjh7oDHTR1dFPb2MH3nnibju4+/vGj8/jY6ZPCLk+Oo6/feauumRe3NPDatkYOtHfT3t3Hwc7IADzA1KIcLpxVwsWzSzijYux7uvIk8YTVIlgJzDCzCqAOWApcd9g+O4BLgHvMbA6QBTQEXJccw+Nv7uZrD1XS2fPHRtms0jzu+MTpTC/JDbEyiVVqinHa5DGcNnkMNx72Ws2+Np7bVM+zmxr41WuRK6OzM1I5d1oh588s5vwZxZQXqbWQTOIxffSDwE+ITA29293/0cxuA1a5+7LoTKG7gFwiA8d/4+5PHeuYahEEw925/ekqfvyHzSwqG8vnz6tgTHYG+aPSmVGaq66fBNTR3ceKrft45u16nt/cQO2BDgAKczIoHZ3FuPwsKopyuGROCWeWF5CmfwMjmi4ok2Pa19rFt5et5/E3d/OxhRP5p4+dSla6ugqSibuzbV8bL2xuYNPeg+xt6WJPcydVDa109/YzJjud988p5epFkzizokAzv0ag4TxYLCFq7erlrheq+cWL1XT29vM3S2bxxQum6T95EjIzphbnMrX43d1/bV29vLilgafW7+V3b+3hodW1VBTlcM0Zk/nk2WW6jiEBqEWQxF6u2sdN961hf1s3Hzx1HF+7bBbTijUGIEfX0d3H8nW7eWDlTl6vaaQwJ4MvXzyd684qIyNN3UbDnbqG5F3ue30H33z0LaYW5/CDq09jweQxYZckI0zlzia+/7u3eaV6P5PGjmLpGZO5csFEJhdkh12aHIWCQIDIypjff+Jtfv5CNRfMLObfrluoq1Bl0NydF7bs445nq3h9WyMAi8vGsmTeOC6bO44phQqF4URBIDS1d3Pz/ZU8v7mB688p41sfnqtZIDJkag+081jlLpZV7mLT3oNAZNrxny2exNIzp2gsYRhQECS5t+qa+cKvVlPf0sW3r5jLJ84qC7skSWDb97fx+w17Wb5uN2/saCIvK43rzpzCh+dPYNa4PI0nhERBkIQa27p5uWofL25p4LHKXRTkZPDTTy7SeIDEVeXOJu56sZrfrdtNf/SWoLPHRZa5+POzyyjO01pI8aIgSCK9ff1893828F+vbsc9covES+aU8ncfmkORFiCTkOxp7mT19gOsq2tmzY4DvF7TSHpKCh9ZOIFrzpjCqRPz1VIImIIgSbR393LTfWv4w8Z6PnHWFK5eNIn5k8a86w5hIsNBdUMrd7+8jd+srqWzp5/MtBTmT8rn4tmlfPa8cq19FAAFQRLY19rF5+5dxbraJv7+ilP483PKwy5J5Lia2rt5Zet+Vm8/wMrtB1i7s4mZpbl8/6r5LJwyNuzyEoqCIMG9Vr2fm++vpKmjm9uXLuSyU8aFXZLIoDz7dj3/65F17Gnp5JNnlbH0zMnMHT9aV7sPAQVBgurrd/71mS3c/vQWygpz+NdrFzJvYn7YZYmclIOdPfzgiU38+vUd9PU700tyuer0SXzuvAqNI5wEBUGCuvn+NTxWuYuPLZzIbR+Zp7naklAa27pZvm43yyp38XpNI6dPGcO/f2IR4/Kzwi5tRDpaEChaR7BVNY08VrmLL100jR9ds0AhIAmnICeDT55dxoNfOId/u24hb+85yIf/9UVWbN0XdmkJRZ8cI5R7ZKmI4rxMvnTR9LDLEQnch+dPYPa4PP7yl6u57q7XGDc6i7kTRnPKhNHMHT+aUybkM7lglMYSBkFBMEI983Y9K2sO8N2PzCM7Q3+Nkhyml+Tx2I3n8eDKnayra2bDrhae39xAX3+ki3t0Vhofmj+Bz/xJOTNL80KuduTQJ8gI1Nfv/OCJTZQXZrP0jMlhlyMSV7mZaXz2vIp3nnf29LFpz0HW72ph1fZGfvtGLfe9voP3zSji5ktmsLi8IMRqRwaNEYxAj66pY9Peg3ztslm6faQkvaz0VE6bPIbrzprCjz6+gFe+cQm3fGAWm/Yc5OqfvcLXH1rL/tausMsc1vQpMsK0dvXyz09tYt7E0Xzo1PFhlyMy7BTkZPCli6bz3C0X8oULpvHomjou+r/PccezVext6Qy7vGFJQTDC/N8nN7G7pZO/v2IeKVo2QuSosjPSuPXy2TzxlfexYMpYfvjkJs793jN8/t6VvFq9P+zyhhUFwQjyxo4D3PtKDdefXcaiMl16LxKL6SV5/Ndnz+TZr1/IDedPZW1tM0vvfJVvP/YWHd19YZc3LCgIRoju3n5uffhNxo3O4pYls8MuR2TEqSjK4W+XzOaFWy7iM39Szr2vbOeDt7/Imh0Hwi4tdAqCEeJnz29l895W/kFXD4uclFEZqXz7T0/h158/i+7efj7+81d4YOWOsMsKlYJgBFhZ08i/PrOFD88fzyVzSsMuRyQhnDu9iOU3vY+zpxbytw+v4zvL1tPb1x92WaFQEAxzu5o6+OKvVjNpbDb/+NFTwy5HJKHkZ6fzn58+g8+dV8E9K2r45H+8RnVDa9hlxZ2CYBjr7OnjL3+5ms6efu66fhH5o9LDLkkk4aSlpvDND8/lh1fPZ31dC0t+8iI/fPJt2rt7wy4tbtTZPEy5O9/47Tre2tXMXX++mOklulxeJEh/tngyF8wq5nvL3+aOZ7fy4KpaLptbyqVzSjlnWiFZ6Yl7x7TAWwRmtsTMNplZlZndeoTXf2xmldGvzWbWFHRNI8Gytbt4ZE0df33pTC6dq3EBkXgoycviR9cs4MG/PIfTp4zhkTV1fOaelZz9f56mqj5xu4wCvR+BmaUCm4H3A7XASuBad99wlP2/DCx0988e67iJfj+ChoNdXPbj5ykvyuE3XzhX9xsWCUlXbx+vbN3PVx6opLwwh4e/OLL/P4Z1P4IzgSp3r3b3buB+4Mpj7H8tcF/ANQ1731m2nrauPn549fwR/Y9OZKTLTEvlwlkl3HblPCp3NnHXi9VhlxSIoINgIrBzwPPa6Lb3MLMyoAJ45iiv32Bmq8xsVUNDw5AXOlz8bt1uHl+3m5svnaFxAZFh4k/nj2fJKeP40VOb2bL3YNjlDLnhNGtoKfAbdz/iNd/ufqe7L3b3xcXFxXEuLT6aO3r45mPrmTdxNDecPzXsckQkysz4h4/OIzcrja8/tDbhrjcIOgjqgIEL5k+KbjuSpSR5t9B/vryNfa1dfO9j87W8tMgwU5SbyXevnMfa2mZuvr+SngQKg6Cnj64EZphZBZEAWApcd/hOZjYbGAu8EnA9w1ZLZw93v7SNy+aWMm9iftjliMgRfGj+eHY3z+EfHt9Id18//3bdQjLTRv600kB/7XT3XuBG4ElgI/Cgu683s9vM7IoBuy4F7vcgpzANc/+1ooaWzl5uumRG2KWIyDF8/n1Tue3KU/j9hr3RCz5H/gqmgV9Q5u7LgeWHbfvWYc+/E3Qdw1lrVy+/eGkbF88uUWtAZAS4/pxy0lNT+MZv13HPihq+cMG0sEs6KeqIHgZ+9ep2mtp7+PLF08MuRURidO2ZUzhnaiG/fGX7iB88VhCErL27l7teqOb8mcUsnKKbzYiMJJ86t5y6pg7+sHFv2KWcFAVByO5ZUcP+tm5uUmtAZMS5dE4JE8eM4p4VNWGXclIUBCFqau/mp89t5ZLZJSwuLwi7HBE5QWmpKVx/ThmvVjeycXdL2OUMmoIgRP/+3FZau3q5ZcmssEsRkUG65ozJZKWncO8IbhUoCEJS19TBPStq+NjCScweNzrsckRkkMZkZ/DRhRN5tLKOA23dYZczKAqCkPzk95sB+OplM0OuRERO1qfOLaezp59/Wr6R/v6RdzmUgiAEW/Ye5OE3arn+7DImjhkVdjkicpJmjxvNjRdN56HVtXx72XpG2rWxukNZCO5ZUUN6agp/dZFmCokkiq9dNpPuvn7ufKGatFTjWx+ei9nIWEZeQRBnHd19LKvcxQdPHU9BTkbY5YjIEDEzvnH5bHr6+vnPl2uYNDabz51XEXZZMVHXUJw9sX43B7t6+fjiycffWURGFLNIS+CsigLuWbFtxIwXKAji7IGVO5lSkM1ZFbpuQCQRmRnXnDGZnY0drKxpDLucmCgI4mj7/jZerW7k44snkaJbUIokrCXzxpGTkcpvVteGXUpMFARx9OCqnaQYXLVoUtiliEiAsjPS+ND88Sxft5v27t6wyzkuBUGc9PU7v1ldy/kzixmfrymjIonuqtMn0dbdxxNv7Qm7lONSEMTJC5sb2NvSxTUaJBZJCmeUFzClIJuH3xj+3UMKgjj5nzd3MzorjUvmlIZdiojEQUqK8bHTJ7Ji637qmjrCLueYFARx0NfvPLepnotml5CRph+5SLK46vRJuMPDw3zQWJ9KcbC2ton9bd1cPLsk7FJEJI4mF2Rz4axi7nqhml3DuFWgIIiDpzfuJTXFuHCmgkAk2dx2xTz63Ln1t+uG7RpECoI4eHpjPYvLxpKfnR52KSISZ1MKs/nG5bN5YXMDD6zcGXY5R6QgCFhdUwdv7znIJXPUGhBJVp84q4xzphbyD49vHJYDxwqCgD0Tvam1ZguJJK+UFOMHV8+n353//ci6sMt5DwVBwJ5+u57ywmymFuWEXYqIhGhyQTZfuXQGz25q4JWt+8Mu510UBAFq7+5lxdb9XDy7dMSsSy4iwbn+nHLG52fxgyffHlYDxwqCAL20ZR/dvf1cqvEBEQGy0lO5+ZIZrNnRxO837A27nHcoCAL0/OYGcjPTWFyuJadFJOLqRZOYWpTDD5/cRN8wuV9B4EFgZkvMbJOZVZnZrUfZ5+NmtsHM1pvZr4OuKV7e2NHEwiljdDWxiLwjLTWFr39gFlvqW3lkTV3Y5QABB4GZpQJ3AJcDc4FrzWzuYfvMAL4B/Im7nwJ8Jcia4qW9u5dNe1pYOHlM2KWIyDBz+bxxnDoxn395evOwaBUE/avqmUCVu1e7ezdwP3DlYfv8BXCHux8AcPf6gGuKi3W1zfQ7LJiiIBCRdzMzvnTRNHY2dgyLsYKgg2AiMPBSutrotoFmAjPN7GUze9XMlhzpQGZ2g5mtMrNVDQ0NAZU7dCp3NgFw2iQFgYi816VzSpk4ZhT3rNgWdimxB4GZjTKzWQHUkAbMAC4ErgXuMrP3fHq6+53uvtjdFxcXFwdQxtCq3NnElIJsCnMzwy5FRIahtNQUrj+njFerG9m4uyXUWmIKAjP7U6ASeCL6fIGZLYvhW+uAgXdimRTdNlAtsMzde9x9G7CZSDCMaGt2NLFA4wMicgxLz5jCqPRU7nm5JtQ6Ym0RfIdIf38TgLtXAhUxfN9KYIaZVZhZBrAUODxAHiXSGsDMioh0FVXHWNewtKe5kz0tnQoCETmm/Ox0Pnr6RB6trKOxrTu0OmINgh53bz5s23GHut29F7gReBLYCDzo7uvN7DYzuyK625PAfjPbADwL3OLuw+v66xNUufMAoIFiETm+z5xbTldvP/e9viO0GtJi3G+9mV0HpEane94ErIjlG919ObD8sG3fGvDYga9GvxLCmp1NpKcac8ePDrsUERnmZpTmcd70In75yna+cME0UlPivxxNrC2CLwOnAF3Ar4FmEmS+fxAqdzQxd0I+WempYZciIiPAny2exJ6Wznd6E+LtuC2C6EVhj7v7RcDfBV/SyNbX76yra+bjiycff2cREeDCWSWkpRi/31DPorL4L0lz3BaBu/cB/WaWH4d6RrzNew/S3t2ngWIRiVn+qHTOmlrA7zfsCeX9Y+0aagXWmdl/mNnth76CLGykOnQhmYJARE7EpXNK2drQRnVDa9zfO9Yg+C3wTeAFYPWALzlM5Y4mxmanU1aYHXYpIjKCXBq9i+HTG+O/yk5Ms4bc/d7odQAzo5s2uXtPcGWNXBv3tHDKhHzdiEZETsjkgmxmj8vj9xv38hfnT43re8d6ZfGFwBYiK4n+O7DZzM4PsK4Ryd2pqm9leklu2KWIyAh02dxSVtU0xv3isli7hv4ZuMzdL3D384EPAD8OrqyRaVdzJ+3dfQoCERmUS+eW0u/w7Nvx7R6KNQjS3X3ToSfuvhlID6akkauqPjLIM0NBICKDMG9CPqWjM/nDxvguTR3rlcWrzOwXwK+izz8BrAqmpJHrUBCoRSAig5GSYlw6p5RH1tTR1dtHZlp8LkqNtUXwRWADkaUlboo+/mJQRY1UVfUHKcjJ0NLTIjJo504ror27jy174zeNNNYWQRrwL+7+I3jnamN92h2mqr6V6cVqDYjI4M0sjXyGbKk/yLyJ8bmON9YWwdPAqAHPRwF/GPpyRi53Z0t9K9PULSQiJ6G8KIf0VGNzHFsEsQZBlru/U1X0sa6YGmB/WzdN7T0aKBaRk5KemkJFUQ5b9h6M23vGGgRtZnb6oSdmtgjoCKakkelQf54GikXkZM0ozYtriyDWMYKvAA+Z2S7AgHHANYFVNQJVRdcHmVGqIBCRkzOzJI/l63bT0d3HqIzgZw7FusTESjObDRy6eb2WmDjM1vpWcjPTGDc6K+xSRGSEm1maiztsbWiNy4BxrEtM/BmRcYK3gI8ADwzsKpLICP+0klytMSQiJ+1Qz8LmOI0TxDpG8E13P2hm5wGXAP8B/DS4skYeTR0VkaFSVhjfmUOxBkFf9M8PAXe5++NARjAljTwtnT3sbenSQLGIDIn01BSmFuXGbeZQrEFQZ2Y/JzJAvNzMMk/gexOe1hgSkaE2ozSXzfXDKwg+DjwJfMDdm4AC4JZDL5rZ2ABqGzGqNHVURIbYzNI8djZ20N7dG/h7xRQE7t7u7r919y3R57vd/akBuzwdSHUjRFVDKxlpKUwu0DV2IjI0Di01cajHIUhD1b2T1FNlqupbmVqUQ2pKUv8YRGQITS/JA4jLgPFQBYEP0XFGpC31B9UtJCJDqrwwm4zUlLgMGGvA9yR19vRRe6BDQSAiQyotNYWpxTlxuZZAXUMnqbqhDXcNFIvI0JtRmseW4TxGYGYDP/kuOcZ+S8xsk5lVmdmtR3j902bWYGaV0a/PD7amMBxaY2iaLiYTkSE2sySX2gMdtHUFO3PoZFoEGw49cPfGI+0QvYHNHcDlwFzgWjObe4RdH3D3BdGvX5xETXFXVd9KikFFUU7YpYhIgpkRp5lDx1x0zsy+erSXgFh+BT4TqHL36ujx7geuZECIjHRbG1qZXJBNVnp87i0qIsmjoijyMVuzv43TJo8J7H2O1yL4J2AskHfYV24M3wswEdg54HltdNvhrjKzN83sN2Y2+UgHMrMbzGyVma1qaGiI4a3jY6vWGBKRgJQVRq5N2ravLdD3Od4y1G8Aj7r76sNfGMK+/P8G7nP3LjP7S+Be4OLDd3L3O4E7ARYvXjwspqv29TvV+9q4YGZx2KWISALKSk9lQn4WNQEHwfF+q68DtpvZzUd4bXEMx68DBv6GPym67R3uvt/du6JPfwEsiuG4w8LOxna6e/s1UCwigSkvyqFmf3ug73G8IJhLZJXRz5rZWDMrOPQFxHJjmpXADDOrMLMMYCmwbOAOZjZ+wNMrgI2xlx+urYdmDGnqqIgEJBIE4XYN/ZzIOkJTgdW8+3oBj24/KnfvNbMbiSxYlwrc7e7rzew2YJW7LwNuMrMrgF6gEfj0YE4kDIdG8nUNgYgEpaIwh6b2HprauxmTHczq/8cMAne/HbjdzH7q7l8czBu4+3Jg+WHbvjXg8TeAbwzm2GGrqm+lOC+T/FHpYZciIgmqPDo1fdu+NhZOCSYIYl19dFAhkOiqGlqZVqzrB0QkOOXRmUNBdg9praFBcvfI1FF1C4lIgCYXZGMG2/YFN2CsIBikhtYuWjp7dQ2BiAQqMoV0VKBTSBUEg/THgeK8kCsRkURXEfDMIQXBIG2tPzR1VGMEIhKs8qJstu1rwz2Ya2kVBIO0taGN3Mw0xo3OCrsUEUlw5YU5HOzs5UB7LJdvnTgFwSBV1UdmDJkl7a0YRCROKgZMIQ2CgmCQtja0amkJEYmLssJIEAQ1YKwgGIT27l52N3dqaQkRiYspBdmkWHDXEigIBqEmOp9XN6MRkXjISEth4thR6hoaTg79ZZQXKghEJD7KC4ObQqogGIRt+yJTR8uLskOuRESSRUVRDjX72gOZQqogGITqfW2Mz88iO+N4i7eKiAyN8sIcWrt62dfaPeTHVhAMwrZ9bRofEJG4OvSZsz2A7iEFwSDUKAhEJM7Ki3IoHZ3Jwa7eIT+2+jZO0IG2bg609ygIRCSuKopyeO1/XRrIsdUiOEHbos0yBYGIJAoFwQna1qAgEJHEoiA4Qdv2tZGaYkwu0NRREUkMCoITtG1/G1MKsklP1Y9ORBKDPs1O0LaGtnfuISoikggUBCfA3aPXEGixORFJHAqCE7C3pYuOnj4qijVQLCKJQ0FwAg4tNjdVM4ZEJIEoCE7AoSDQ1FERSSQKghOwbV8rmWkpuk+xiCQUBcEJOLTYXEqK7lMsIokj8CAwsyVmtsnMqszs1mPsd5WZuZktDrqmwarWYnMikoACDQIzSwXuAC4H5gLXmtncI+yXB9wMvBZkPSejt6+fnY3tlCsIRCTBBN0iOBOocvdqd+8G7geuPMJ+3wW+D3QGXM+g7TzQQU+fa8aQiCScoINgIrBzwPPa6LZ3mNnpwGR3f/xYBzKzG8xslZmtamhoGPpKj6O6IXJ7yqnFuphMRBJLqIPFZpYC/Aj42vH2dfc73X2xuy8uLi4OvrjDVEdXHZ2mi8lEJMEEHQR1wOQBzydFtx2SB8wDnjOzGuBsYNlwHDCu3tdKQU4GY7Izwi5FRGRIBR0EK4EZZlZhZhnAUmDZoRfdvdndi9y93N3LgVeBK9x9VcB1nbCtDW0aHxCRhBRoELh7L3Aj8BRJgA4AAAo0SURBVCSwEXjQ3deb2W1mdkWQ7z3UqhvamKpuIRFJQIHfs9jdlwPLD9v2raPse2HQ9QxGS2cP+1q7NFAsIglJVxbH4NBAsbqGRCQRKQhioKmjIpLIFAQxqG6I3Kd4iu5TLCIJSEEQg+p9rUwpyCYjTT8uEUk8+mSLQbWmjopIAlMQHEd/v7+z/LSISCJSEBxHXVMHXb39GigWkYSlIDiO6kP3KdbFZCKSoBQEx/HHqaMKAhFJTAqC46huaCMvM43i3MywSxERCYSC4Diq97UytTgHM92nWEQSk4LgOCKLzWmgWEQSl4LgGNq7e9nd3KlrCEQkoSkIjmHTnoMAzChVi0BEEpeC4BjerG0G4LTJY0KuREQkOAqCY1i7s4nivEzGjc4KuxQRkcAoCI5hbW0Tp00aoxlDIpLQFARH0dLZw9aGNk6blB92KSIigVIQHMVbGh8QkSShIDiKytomAOarRSAiCU5BcBRv7mymvDCbMdkZYZciIhIoBcFRrK1tYv4kdQuJSOJTEBxBfUsnu5s7NT4gIklBQXAEaw8NFGt8QESSgILgCN6sbSI1xThlgoJARBKfguAIKnc2MbM0j1EZqWGXIiISOAXBYdydN2ubWTBZrQERSQ6BB4GZLTGzTWZWZWa3HuH1L5jZOjOrNLOXzGxu0DUdS83+dpo7ejRjSESSRqBBYGapwB3A5cBc4NojfND/2t1PdfcFwA+AHwVZ0/E8vXEvAGdPLQyzDBGRuAm6RXAmUOXu1e7eDdwPXDlwB3dvGfA0B/CAazqmxyp3MX9SPhW6GY2IJImgg2AisHPA89rotncxsy+Z2VYiLYKbjnQgM7vBzFaZ2aqGhoZAit3a0Mq6umauOG1CIMcXERmOhsVgsbvf4e7TgL8F/vdR9rnT3Re7++Li4uJA6nischdmKAhEJKkEHQR1wOQBzydFtx3N/cBHAq3oKNydZZV1nDutkBLdiEZEkkjQQbASmGFmFWaWASwFlg3cwcxmDHj6IWBLwDUd0draZmr2t3Plgvf0XImIJLS0IA/u7r1mdiPwJJAK3O3u683sNmCVuy8DbjSzS4Ee4ADwqSBrOprHKuvISEthybxxYby9iEhoAg0CAHdfDiw/bNu3Bjy+Oegajqev3/nvtbu5eFYJo7PSwy5HRCSuhsVgcdgefqOWfa1dfGShBolFJPkkfRAsW7uLWx9+kzPLC7h4dmnY5YiIxF3gXUPD2WOVdfz1A5WcUV7A3Z8+g4y0pM9FEUlCSRUEP3t+Kw+vrgUily9XN7RyZkUkBLIzkupHISLyjqT69CvKzWRGae47z983o4hbPjBLISAiSS2pPgGvXjSJqxdNCrsMEZFhRZ3iIiJJTkEgIpLkFAQiIklOQSAikuQUBCIiSU5BICKS5BQEIiJJTkEgIpLkzD3Ue8UPipk1ANtP4FuKgH0BlTOc6byTS7KeNyTvuZ/oeZe5+3vu9Tsig+BEmdkqd18cdh3xpvNOLsl63pC85z5U562uIRGRJKcgEBFJcskSBHeGXUBIdN7JJVnPG5L33IfkvJNijEBERI4uWVoEIiJyFAoCEZEkl1BBYGZLzGyTmVWZ2a1HeD3TzB6Ivv6amZXHv8qhF8N5f9XMNpjZm2b2tJmVhVHnUDveeQ/Y7yozczNLiOmFsZy3mX08+ne+3sx+He8agxDDv/MpZvasma2J/lv/YBh1DjUzu9vM6s3sraO8bmZ2e/Tn8qaZnX7Cb+LuCfEFpAJbgalABrAWmHvYPn8F/Cz6eCnwQNh1x+m8LwKyo4+/mCznHd0vD3gBeBVYHHbdcfr7ngGsAcZGn5eEXXeczvtO4IvRx3OBmrDrHqJzPx84HXjrKK9/EPgdYMDZwGsn+h6J1CI4E6hy92p37wbuB648bJ8rgXujj38DXGJmFscag3Dc83b3Z929Pfr0VSAR7tcZy983wHeB7wOd8SwuQLGc918Ad7j7AQB3r49zjUGI5bwdGB19nA/simN9gXH3F4DGY+xyJfBfHvEqMMbMxp/IeyRSEEwEdg54XhvddsR93L0XaAYK41JdcGI574E+R+S3h5HuuOcdbSJPdvfH41lYwGL5+54JzDSzl83sVTNbErfqghPLeX8H+KSZ1QLLgS/Hp7TQnehnwHsk1c3rk52ZfRJYDFwQdi1BM7MU4EfAp0MuJQxpRLqHLiTS+nvBzE5196ZQqwretcA97v7PZnYO8Eszm+fu/WEXNtwlUougDpg84Pmk6LYj7mNmaUSaj/vjUl1wYjlvzOxS4O+AK9y9K061Bel4550HzAOeM7MaIn2nyxJgwDiWv+9aYJm797j7NmAzkWAYyWI5788BDwK4+ytAFpFF2RJdTJ8Bx5JIQbASmGFmFWaWQWQweNlh+ywDPhV9fDXwjEdHW0aw4563mS0Efk4kBBKhvxiOc97u3uzuRe5e7u7lRMZGrnD3VeGUO2Ri+Xf+KJHWAGZWRKSrqDqeRQYglvPeAVwCYGZziARBQ1yrDMcy4Pro7KGzgWZ3330iB0iYriF37zWzG4EnicwwuNvd15vZbcAqd18G/AeR5mIVkcGXpeFVPDRiPO8fArnAQ9Gx8R3ufkVoRQ+BGM874cR43k8Cl5nZBqAPuMXdR3TLN8bz/hpwl5n9NZGB408nwC96mNl9RIK9KDr+8W0gHcDdf0ZkPOSDQBXQDnzmhN8jAX5OIiJyEhKpa0hERAZBQSAikuQUBCIiSU5BICKS5BQEIiJJTkEgScXMCs2sMvq1x8zqoo+botMth/r9vmNmXz/B72k9yvZ7zOzqoalM5I8UBJJU3H2/uy9w9wXAz4AfRx8vAI67FEH0inSRhKIgEPmjVDO7K7qG/1NmNgrAzJ4zs5+Y2SrgZjNbZGbPm9lqM3vy0EqPZnbTgPs+3D/guHOjx6g2s5sObbTIfSLein595fBioleK/lt0Df4/ACUBn78kKf12I/JHM4Br3f0vzOxB4CrgV9HXMtx9sZmlA88DV7p7g5ldA/wj8FngVqDC3bvMbMyA484mck+IPGCTmf0UmE/kCtCziKwj/5qZPe/uawZ830eBWUTW1i8FNgB3B3LmktQUBCJ/tM3dK6OPVwPlA157IPrnLCKL2f0+ulxHKnBoXZc3gf9nZo8SWe/nkMejC/11mVk9kQ/184BH3L0NwMx+C7yPyA1lDjkfuM/d+4BdZvbMkJylyGEUBCJ/NHBV1j5g1IDnbdE/DVjv7ucc4fs/ROTD+0+BvzOzU49yXP2/k2FFYwQiJ2YTUBxd7x4zSzezU6L3P5js7s8Cf0tkifPcYxznReAjZpZtZjlEuoFePGyfF4BrzCw1Og5x0VCfjAjoNxORE+Lu3dEpnLebWT6R/0M/IbLm/6+i2wy43d2bjnYnVHd/w8zuAV6PbvrFYeMDAI8AFxMZG9gBvDLU5yMCWn1URCTpqWtIRCTJKQhERJKcgkBEJMkpCEREkpyCQEQkySkIRESSnIJARCTJ/X8Rg7GgWF9KKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvo20EjjIDYr",
        "colab_type": "code",
        "outputId": "7e66bf66-c4f0-4da7-adfa-eabeb6d5400a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# output submission\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "preds = model.predict(vector_test)\n",
        "\n",
        "if not threshold:\n",
        "    threshold = 0.3\n",
        "preds = (preds >= threshold).astype(int)\n",
        "sub.target = preds\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "\n",
        "labels = pd.read_csv('labels.csv').target\n",
        "print(\"The submission f1_score is: \", f1_score(labels, preds, average='weighted'))\n",
        "# submission result\n",
        "# GRU 64, max_features = 10000, embed_size=128, max_len=150, no embed, f1_score 0.75460\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Twitter 300, train_size 0.9 (default 0.8), f1_score 0.81083\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Google news 300, train_size 0.9 (default 0.8), f1_score 0.80195\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Google news 300, train_size 0.8 , f1_score 0.80826\n",
        "# GRU 64, max_features = 10000, embed_size=300, max_len=150, Glove wiki 300, train_size 0.8 , f1_score 0.81352\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The submission f1_score is:  0.803438282754104\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0 22746    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "\n",
            "## Received: \"tweets.csv\"\n",
            "\n",
            "100 22775    0    29  100 22746     19  15073  0:00:01  0:00:01 --:--:-- 15082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlFzsb2GLEJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload to vps server\n",
        "!curl -X PUT --upload-file submission.csv ali.140714.xyz:8000/tweets.csv \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}