{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP with Disaster Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQjkhns4DDCG1wcmZuT0sR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaoangLiu/ipynb/blob/master/NLP_with_Disaster_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJNib6SIAGVa",
        "colab_type": "text"
      },
      "source": [
        "# NLP with Disaster Tweets\n",
        "\n",
        "Kaggle contest page: https://www.kaggle.com/c/nlp-getting-started/overview\n",
        "\n",
        "Task: predicts which Tweets are about real disasters and which one’s aren’t. Return value is either 1 (real) or 0 (unreal) .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q8SHrDH_8Pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cfff8eab-5d1d-4513-f776-e220cd39d4b6"
      },
      "source": [
        "# Load packages \n",
        "import math\n",
        "import re\n",
        "import os\n",
        "import timeit\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import logging\n",
        "import time\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "logging.basicConfig(format='[%(asctime)s %(levelname)8s] %(message)s', level=logging.INFO, datefmt='%m-%d %H:%M:%S')\n",
        "\n",
        "from keras import layers, Input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, LSTM, GRU, Bidirectional\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import gensim.downloader as api\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n",
            "[05-13 03:28:35     INFO] 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJLCawmzA1WS",
        "colab_type": "text"
      },
      "source": [
        "## Explore data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ldINPVLA5Yg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a51c566a-fa14-403d-f875-6187c398bc2b"
      },
      "source": [
        "! wget -O tweets.zip ali.140714.xyz:8000/nlp-getting-started.zip \n",
        "! unzip tweets.zip \n",
        "! ls\n",
        "! wget -O labels.csv ali.140714.xyz:8000/leaked_tweet_labels.csv\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-13 05:59:28--  http://ali.140714.xyz:8000/leaked_tweet_labels.csv\n",
            "Resolving ali.140714.xyz (ali.140714.xyz)... 47.240.16.188\n",
            "Connecting to ali.140714.xyz (ali.140714.xyz)|47.240.16.188|:8000... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22746 (22K) [text/csv]\n",
            "Saving to: ‘labels.csv’\n",
            "\n",
            "labels.csv          100%[===================>]  22.21K   131KB/s    in 0.2s    \n",
            "\n",
            "2020-05-13 05:59:28 (131 KB/s) - ‘labels.csv’ saved [22746/22746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxzysppNBDne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "ed81af6d-91bf-42ff-869c-276ae8ed7313"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train.target.value_counts() \n",
        "\"\"\" \n",
        "0    4342\n",
        "1    3271\n",
        "Name: target, dtype: int64\n",
        "Good, so the data is WELL balanced\n",
        "\"\"\"\n",
        "train.keyword.value_counts()\n",
        "train.text.str.len().nsmallest(30)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1882     7\n",
              "4890     7\n",
              "5115     7\n",
              "24       8\n",
              "30       8\n",
              "3670     8\n",
              "4971     8\n",
              "28       9\n",
              "3667     9\n",
              "3749    10\n",
              "6705    10\n",
              "22      11\n",
              "4735    11\n",
              "5184    11\n",
              "6015    11\n",
              "784     12\n",
              "6522    12\n",
              "6917    12\n",
              "7470    12\n",
              "16      13\n",
              "2496    13\n",
              "3696    13\n",
              "15      14\n",
              "849     14\n",
              "6174    14\n",
              "6277    14\n",
              "7589    14\n",
              "900     15\n",
              "6224    15\n",
              "6258    15\n",
              "Name: text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inq21zEjCoPF",
        "colab_type": "text"
      },
      "source": [
        "# CNN\n",
        "Dive into the data, build a baseline model with CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLxdiCYSCzEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base class for classifier\n",
        "class Classifier():\n",
        "  def __init__(self):\n",
        "    self.train = None\n",
        "    self.test = None \n",
        "    self.model = None\n",
        "\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "  \n",
        "  def countvectorize(self):\n",
        "      tv = TfidfVectorizer(ngram_range=(1,3), token_pattern=r'\\w{1,}',\n",
        "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1, max_features=5000)\n",
        "      tv = CountVectorizer()\n",
        "      tv.fit(self.train.question_text)\n",
        "      self.vector_train = tv.transform(self.train.question_text)\n",
        "      self.vector_test  = tv.transform(self.test.question_text)\n",
        "      logging.info(\"Train & test text tokenized\")\n",
        "\n",
        "  def build_model(self):\n",
        "      pass\n",
        "\n",
        "  def run_model(self):\n",
        "      # Choose your own classifier: self.model and run it\n",
        "      logging.info(f\"{self.__class__.__name__} starts running.\")\n",
        "      labels = self.train.target\n",
        "      x_train, x_val, y_train, y_val = train_test_split(self.vector_train, labels, test_size=0.2, random_state=2090)\n",
        "      self.model.fit(x_train, y_train)\n",
        "      y_preds = self.model.predict(x_val)\n",
        "\n",
        "      logging.info(f\"Accuracy score: {accuracy_score(y_val, y_preds)}\")\n",
        "      logging.info(f\"Confusion matrix: \") \n",
        "      print(confusion_matrix(y_val, y_preds))\n",
        "      print(\"Classificaiton report:\\n\", classification_report(y_val, y_preds, target_names=[\"Sincere\", \"Insincere\"]))\n",
        "      # y_preds = self.model.predict(self.vector_test)\n",
        "      return y_preds\n",
        "\n",
        "  def save_predictions(self, y_preds):\n",
        "      sub = pd.read_csv(f\"sample_submission.csv\")\n",
        "      sub['prediction'] = y_preds \n",
        "      sub.to_csv(f\"submission_{self.__class__.__name__}.csv\", index=False)\n",
        "      logging.info('Prediction exported to submisison.csv')\n",
        "  \n",
        "  def pipeline(self):\n",
        "      s_time = time.clock()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "      self.build_model()\n",
        "      self.save_predictions(self.run_model())\n",
        "      logging.info(f\"Program running for {time.clock() - s_time} seconds\")\n",
        "\n",
        "class C_Bayes(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = MultinomialNB()\n",
        "      return self.model\n",
        "\n",
        "# Logistic Regression \n",
        "class C_LR(Classifier):\n",
        "  def build_model(self):\n",
        "      self.model = LogisticRegression(n_jobs=10, solver='lbfgs', C=0.1, verbose=1)\n",
        "      return self.model\n",
        "\n",
        "class C_SVM(Classifier):\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" Load train, test csv files and return pandas.DataFrame\n",
        "      \"\"\"\n",
        "      self.train = pd.read_csv(train_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      self.train = self.train.sample(100000)\n",
        "      self.test = pd.read_csv(test_file, engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "\n",
        "  def build_model(self):\n",
        "      self.model = svm.SVC()\n",
        "      return self.model\n",
        "\n",
        "class C_Ensemble(Classifier):\n",
        "  def ensemble(self):\n",
        "      s_time = time.perf_counter()\n",
        "      self.load_data()\n",
        "      self.countvectorize()\n",
        "\n",
        "      nb = MultinomialNB()\n",
        "      lr = LogisticRegression(n_jobs=10, solver='saga', C=0.1, verbose=1)\n",
        "      svc = svm.SVC()\n",
        "\n",
        "      all_preds = [0] * self.test.shape[0]\n",
        "      for m in (nb, lr, svc):\n",
        "          self.model = m\n",
        "          if m == svc: \n",
        "              self.load_data()\n",
        "              self.train = self.train.sample(10000)\n",
        "              self.countvectorize()\n",
        "          all_preds += self.run_model()\n",
        "\n",
        "      all_preds = [1 if p > 0 else 0 for p in all_preds]\n",
        "      self.save_predictions(all_preds)\n",
        "      logging.info(f\"Program running for {time.perf_counter() - s_time} seconds\")\n",
        "\n",
        "\n",
        "class Helper():\n",
        "    def locate_threshold(self, model, x_val, y_val):\n",
        "        y_probs = model.predict(x_val, batch_size=1024, verbose=1)\n",
        "        best_threshold = best_f1 = pre_f1 = 0\n",
        "        history = []\n",
        "\n",
        "        for i in np.arange(0.01, 1, 0.01):\n",
        "          if len(y_probs[0]) >= 2:\n",
        "              y2_preds = [1 if e[1] >= i else 0 for e in y_probs]\n",
        "          else:\n",
        "              y2_preds = (y_probs > i).astype(int)\n",
        "\n",
        "          cur_f1 = f1_score(y_val, y2_preds, average='weighted')\n",
        "          history.append((i, cur_f1))\n",
        "          symbol = '+' if cur_f1 >= pre_f1 else '-'\n",
        "          print(\"Threshold {:6.4f}, f1_score: {:<0.8f}  {} {:<0.6f} \".format(i, cur_f1, symbol, abs(cur_f1 - pre_f1)))\n",
        "          pre_f1 = cur_f1\n",
        "\n",
        "          if cur_f1 >= best_f1:\n",
        "              best_f1 = cur_f1\n",
        "              best_threshold = i\n",
        "\n",
        "        print(f\"Best f1 score {best_f1}, best threshold {best_threshold}\")\n",
        "        plt.xlabel('Threshold')\n",
        "        plt.ylabel('f1_score')\n",
        "        plt.plot(*zip(*history))\n",
        "\n",
        "        return best_threshold\n",
        "\n",
        "class C_NN(Classifier):\n",
        "    def __init__(self, max_features=100000, embed_size=128, max_len=300):\n",
        "        self.max_features=max_features\n",
        "        self.embed_size=embed_size\n",
        "        self.max_len=max_len\n",
        "    \n",
        "    def tokenize_text(self, text_train, text_test):\n",
        "        '''@para: max_features, the most commenly used words in data set\n",
        "        @input are vector of text\n",
        "        '''\n",
        "        tokenizer = Tokenizer(num_words=self.max_features)\n",
        "        text = pd.concat([text_train, text_test])\n",
        "        tokenizer.fit_on_texts(text)\n",
        "\n",
        "        sequence_train = tokenizer.texts_to_sequences(text_train)\n",
        "        tokenized_train = pad_sequences(sequence_train, maxlen=self.max_len)\n",
        "        logging.info('Train text tokeninzed')\n",
        "\n",
        "        sequence_test = tokenizer.texts_to_sequences(text_test)\n",
        "        tokenized_test = pad_sequences(sequence_test, maxlen=self.max_len)\n",
        "        logging.info('Test text tokeninzed')\n",
        "        return tokenized_train, tokenized_test, tokenizer\n",
        "      \n",
        "    def build_model(self, embed_matrix=[]):\n",
        "        text_input = Input(shape=(self.max_len, ))\n",
        "        embed_text = layers.Embedding(self.max_features, self.embed_size)(text_input)\n",
        "        if len(embed_matrix) > 0:\n",
        "            embed_text = layers.Embedding(self.max_features, self.embed_size, \\\n",
        "                                          weights=[embed_matrix], trainable=False)(text_input)\n",
        "            \n",
        "\n",
        "        branch_a = layers.Bidirectional(layers.GRU(64, return_sequences=True))(embed_text)\n",
        "        branch_b = layers.GlobalMaxPool1D()(branch_a)\n",
        "\n",
        "        branch_c = layers.Dense(64, activation='relu')(branch_b)\n",
        "        branch_d = layers.Dropout(0.2)(branch_c)\n",
        "        branch_z = layers.Dense(1, activation='sigmoid')(branch_d)\n",
        "        \n",
        "        model = Model(inputs=text_input, outputs=branch_z)\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "        \n",
        "    def embed_word_vector(self, word_index, model='glove-wiki-gigaword-100'):\n",
        "        glove = api.load(model) # default: wikipedia 6B tokens, uncased\n",
        "        zeros = [0] * self.embed_size\n",
        "        matrix = np.zeros((self.max_features, self.embed_size))\n",
        "          \n",
        "        for word, i in word_index.items(): \n",
        "            if i >= self.max_features or word not in glove: continue # matrix[0] is zeros, that's also why >= is here\n",
        "            matrix[i] = glove[word]\n",
        "\n",
        "        logging.info('Matrix with embedded word vector created')\n",
        "        return matrix\n",
        "\n",
        "    def run(self, x_train, y_train):\n",
        "        checkpoint = ModelCheckpoint('weights_base_best.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "        early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
        "\n",
        "        self.model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.8, random_state=2020)\n",
        "        BATCH_SIZE = max(16, 2 ** int(math.log(len(X_tra) / 100, 2)))\n",
        "        logging.info(f\"Batch size is set to {BATCH_SIZE}\")\n",
        "        history = self.model.fit(X_tra, y_tra, epochs=2, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), \\\n",
        "                              callbacks=[checkpoint, early], verbose=1)\n",
        "\n",
        "        y_pred = self.model.predict(X_val, batch_size=64, verbose=1)\n",
        "        y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "        print(classification_report(y_val, y_pred_bool))\n",
        "        return history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMYEiF3dDgsO",
        "colab_type": "text"
      },
      "source": [
        "Build a simple model and run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNhLSNSDksb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b8677799-b925-42e6-cbef-2785005859fc"
      },
      "source": [
        "c = C_NN(max_features=10000, embed_size=200, max_len=150)\n",
        "c.load_data()\n",
        "vector_train, vector_test, tokenizer = c.tokenize_text(c.train.text, c.test.text)\n",
        "\n",
        "matrix = c.embed_word_vector(tokenizer.word_index, 'glove-twitter-200')\n",
        "model = c.build_model(matrix)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05-13 03:54:57     INFO] CSV data loaded\n",
            "[05-13 03:54:57     INFO] Train text tokeninzed\n",
            "[05-13 03:54:57     INFO] Test text tokeninzed\n",
            "[05-13 03:54:57     INFO] Creating /root/gensim-data\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.1% 751.8/758.5MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[05-13 03:56:14     INFO] glove-twitter-200 downloaded\n",
            "[05-13 03:56:14     INFO] loading projection weights from /root/gensim-data/glove-twitter-200/glove-twitter-200.gz\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "[05-13 04:00:07     INFO] loaded (1193514, 200) matrix from /root/gensim-data/glove-twitter-200/glove-twitter-200.gz\n",
            "[05-13 04:00:07     INFO] Matrix with embedded word vector created\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awAEHBpsEQOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "12af8878-08ad-42c6-aeb4-d8dff7d9d361"
      },
      "source": [
        "X_tra, X_val, y_tra, y_val = train_test_split(vector_train, c.train.target, train_size=0.95, random_state=2020)\n",
        "history = model.fit(X_tra, y_tra, epochs=3, batch_size=32, validation_data=(X_val, y_val))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7232 samples, validate on 381 samples\n",
            "Epoch 1/3\n",
            "7232/7232 [==============================] - 125s 17ms/step - loss: 0.1058 - accuracy: 0.9678 - val_loss: 0.1921 - val_accuracy: 0.9370\n",
            "Epoch 2/3\n",
            "7232/7232 [==============================] - 124s 17ms/step - loss: 0.0991 - accuracy: 0.9683 - val_loss: 0.2299 - val_accuracy: 0.9239\n",
            "Epoch 3/3\n",
            "7232/7232 [==============================] - 124s 17ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.2533 - val_accuracy: 0.9108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgatqwT1Foif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e54c7f6c-3799-46e8-f13d-e3bc42510720"
      },
      "source": [
        "# Find maximum threshold \n",
        "threshold = Helper().locate_threshold(model, X_val, y_val)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r381/381 [==============================] - 0s 171us/step\n",
            "Threshold 0.0100, f1_score: 0.71551724  + 0.715517 \n",
            "Threshold 0.0200, f1_score: 0.75972540  + 0.044208 \n",
            "Threshold 0.0300, f1_score: 0.78758950  + 0.027864 \n",
            "Threshold 0.0400, f1_score: 0.80097087  + 0.013381 \n",
            "Threshold 0.0500, f1_score: 0.81296758  + 0.011997 \n",
            "Threshold 0.0600, f1_score: 0.82653061  + 0.013563 \n",
            "Threshold 0.0700, f1_score: 0.83204134  + 0.005511 \n",
            "Threshold 0.0800, f1_score: 0.84073107  + 0.008690 \n",
            "Threshold 0.0900, f1_score: 0.85638298  + 0.015652 \n",
            "Threshold 0.1000, f1_score: 0.86327078  + 0.006888 \n",
            "Threshold 0.1100, f1_score: 0.86792453  + 0.004654 \n",
            "Threshold 0.1200, f1_score: 0.87738420  + 0.009460 \n",
            "Threshold 0.1300, f1_score: 0.87431694  - 0.003067 \n",
            "Threshold 0.1400, f1_score: 0.88642659  + 0.012110 \n",
            "Threshold 0.1500, f1_score: 0.88888889  + 0.002462 \n",
            "Threshold 0.1600, f1_score: 0.89075630  + 0.001867 \n",
            "Threshold 0.1700, f1_score: 0.88764045  - 0.003116 \n",
            "Threshold 0.1800, f1_score: 0.89014085  + 0.002500 \n",
            "Threshold 0.1900, f1_score: 0.89265537  + 0.002515 \n",
            "Threshold 0.2000, f1_score: 0.89265537  + 0.000000 \n",
            "Threshold 0.2100, f1_score: 0.89265537  + 0.000000 \n",
            "Threshold 0.2200, f1_score: 0.89772727  + 0.005072 \n",
            "Threshold 0.2300, f1_score: 0.90028490  + 0.002558 \n",
            "Threshold 0.2400, f1_score: 0.90285714  + 0.002572 \n",
            "Threshold 0.2500, f1_score: 0.91066282  + 0.007806 \n",
            "Threshold 0.2600, f1_score: 0.91329480  + 0.002632 \n",
            "Threshold 0.2700, f1_score: 0.91014493  - 0.003150 \n",
            "Threshold 0.2800, f1_score: 0.91014493  + 0.000000 \n",
            "Threshold 0.2900, f1_score: 0.90697674  - 0.003168 \n",
            "Threshold 0.3000, f1_score: 0.90962099  + 0.002644 \n",
            "Threshold 0.3100, f1_score: 0.90962099  + 0.000000 \n",
            "Threshold 0.3200, f1_score: 0.90643275  - 0.003188 \n",
            "Threshold 0.3300, f1_score: 0.90909091  + 0.002658 \n",
            "Threshold 0.3400, f1_score: 0.90855457  - 0.000536 \n",
            "Threshold 0.3500, f1_score: 0.91124260  + 0.002688 \n",
            "Threshold 0.3600, f1_score: 0.91124260  + 0.000000 \n",
            "Threshold 0.3700, f1_score: 0.91124260  + 0.000000 \n",
            "Threshold 0.3800, f1_score: 0.90090090  - 0.010342 \n",
            "Threshold 0.3900, f1_score: 0.90090090  + 0.000000 \n",
            "Threshold 0.4000, f1_score: 0.89759036  - 0.003311 \n",
            "Threshold 0.4100, f1_score: 0.89759036  + 0.000000 \n",
            "Threshold 0.4200, f1_score: 0.89759036  + 0.000000 \n",
            "Threshold 0.4300, f1_score: 0.89425982  - 0.003331 \n",
            "Threshold 0.4400, f1_score: 0.89425982  + 0.000000 \n",
            "Threshold 0.4500, f1_score: 0.89425982  + 0.000000 \n",
            "Threshold 0.4600, f1_score: 0.89090909  - 0.003351 \n",
            "Threshold 0.4700, f1_score: 0.89634146  + 0.005432 \n",
            "Threshold 0.4800, f1_score: 0.89634146  + 0.000000 \n",
            "Threshold 0.4900, f1_score: 0.89634146  + 0.000000 \n",
            "Threshold 0.5000, f1_score: 0.89634146  + 0.000000 \n",
            "Threshold 0.5100, f1_score: 0.89634146  + 0.000000 \n",
            "Threshold 0.5200, f1_score: 0.89634146  + 0.000000 \n",
            "Threshold 0.5300, f1_score: 0.89296636  - 0.003375 \n",
            "Threshold 0.5400, f1_score: 0.89570552  + 0.002739 \n",
            "Threshold 0.5500, f1_score: 0.89230769  - 0.003398 \n",
            "Threshold 0.5600, f1_score: 0.88888889  - 0.003419 \n",
            "Threshold 0.5700, f1_score: 0.88473520  - 0.004154 \n",
            "Threshold 0.5800, f1_score: 0.88473520  + 0.000000 \n",
            "Threshold 0.5900, f1_score: 0.88125000  - 0.003485 \n",
            "Threshold 0.6000, f1_score: 0.87774295  - 0.003507 \n",
            "Threshold 0.6100, f1_score: 0.87774295  + 0.000000 \n",
            "Threshold 0.6200, f1_score: 0.87421384  - 0.003529 \n",
            "Threshold 0.6300, f1_score: 0.87421384  + 0.000000 \n",
            "Threshold 0.6400, f1_score: 0.87066246  - 0.003551 \n",
            "Threshold 0.6500, f1_score: 0.87066246  + 0.000000 \n",
            "Threshold 0.6600, f1_score: 0.87619048  + 0.005528 \n",
            "Threshold 0.6700, f1_score: 0.87619048  + 0.000000 \n",
            "Threshold 0.6800, f1_score: 0.87261146  - 0.003579 \n",
            "Threshold 0.6900, f1_score: 0.87261146  + 0.000000 \n",
            "Threshold 0.7000, f1_score: 0.86900958  - 0.003602 \n",
            "Threshold 0.7100, f1_score: 0.86900958  + 0.000000 \n",
            "Threshold 0.7200, f1_score: 0.86900958  + 0.000000 \n",
            "Threshold 0.7300, f1_score: 0.87179487  + 0.002785 \n",
            "Threshold 0.7400, f1_score: 0.86816720  - 0.003628 \n",
            "Threshold 0.7500, f1_score: 0.85714286  - 0.011024 \n",
            "Threshold 0.7600, f1_score: 0.85714286  + 0.000000 \n",
            "Threshold 0.7700, f1_score: 0.85342020  - 0.003723 \n",
            "Threshold 0.7800, f1_score: 0.85342020  + 0.000000 \n",
            "Threshold 0.7900, f1_score: 0.84590164  - 0.007519 \n",
            "Threshold 0.8000, f1_score: 0.84488449  - 0.001017 \n",
            "Threshold 0.8100, f1_score: 0.83333333  - 0.011551 \n",
            "Threshold 0.8200, f1_score: 0.83333333  + 0.000000 \n",
            "Threshold 0.8300, f1_score: 0.82154882  - 0.011785 \n",
            "Threshold 0.8400, f1_score: 0.81632653  - 0.005222 \n",
            "Threshold 0.8500, f1_score: 0.81632653  + 0.000000 \n",
            "Threshold 0.8600, f1_score: 0.80821918  - 0.008107 \n",
            "Threshold 0.8700, f1_score: 0.79584775  - 0.012371 \n",
            "Threshold 0.8800, f1_score: 0.79584775  + 0.000000 \n",
            "Threshold 0.8900, f1_score: 0.78321678  - 0.012631 \n",
            "Threshold 0.9000, f1_score: 0.77464789  - 0.008569 \n",
            "Threshold 0.9100, f1_score: 0.75714286  - 0.017505 \n",
            "Threshold 0.9200, f1_score: 0.76258993  + 0.005447 \n",
            "Threshold 0.9300, f1_score: 0.76086957  - 0.001720 \n",
            "Threshold 0.9400, f1_score: 0.75182482  - 0.009045 \n",
            "Threshold 0.9500, f1_score: 0.72862454  - 0.023200 \n",
            "Threshold 0.9600, f1_score: 0.70454545  - 0.024079 \n",
            "Threshold 0.9700, f1_score: 0.68461538  - 0.019930 \n",
            "Threshold 0.9800, f1_score: 0.66929134  - 0.015324 \n",
            "Threshold 0.9900, f1_score: 0.59751037  - 0.071781 \n",
            "Best f1 score 0.9132947976878611, best threshold 0.26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU9b3/8dcnGwkBEiDsCfsuuxGwuGDdqK3iXtD21tbWW1u72fq79rZVq9eu2toF22rrcu1VtHUpbamodV+whFWCgOwk7EvCGsjy+f0xAx1iAgPkzJlJ3s/HYx7M2eZ8Duh85rubuyMiItKQtLADEBGR5KUkISIijVKSEBGRRilJiIhIo5QkRESkURlhB9CUCgoKvHfv3mGHISKSUubOnbvN3Ts1dKxZJYnevXtTUlISdhgiIinFzNY2dkzVTSIi0iglCRERaZSShIiINEpJQkREGqUkISIijVKSEBGRRilJiIhIo5Qk5ITNXbuT5+aXU11bF3YoIhKQZjWYThJj6aZd3DNrGS+9vwWA3762kh9dMYJRRfmB3nfvgRqWbtrd4LG8nEz6d24T6P1FWiIlCTkuv3l1JT+ZtZQ2rTK45cJB9O6Yy11/W8Jl97/FZaN70KltKwDaZGVw7fhedMjNOuL61dv2smt/NQBpZgzq2pasjKMXaA/W1PH4u2v51csr2L73YIPnmMFfvjyBEYXBJiqRlkZJQuJWuqGSe15YxgVDu/DjK0aQ3zqSAM4aWMBPnl/GM/PKqKmLrHR4sLaOh99ew+0XD+WSkd1Ztnk3P31+Gf9cuuWIz+zXKZcfXzGC4t4dAFhUVsHPX1zOhooquuZl07VdNrNXb2ft9n2c3rcj103oTXZm+hGfUVfnfG36fKa9soLffbo4AX8TIi2HNaflS4uLi11zNwWjts657P632FCxn5duPvtwgmjM0k27uPXp91iwvoLBXduybPNu2rbK4D/P7seQbm0B2Lm3mp+9uJzyiv1cO64nFfuq+ft7G+mQm8WYnu3Zsrsqmixa8c0LBjFxYCfMrMH7/eyFZfzy5RW88I2zGNilbZM/v0hzZmZz3b3BX1gqSUhcHn5rNYvKKvnl1NHHTBAAg7u24+kbP8L/vrOGP85ey3+e1Y8bz+5HXuvMI86bNKwr97ywjEfeXkNOZjpf/Wh/vnBWX9pmZzb8wY347IQ+/P7N1dz/ygrumzL6uK4VkcYFXpIws0nAL4B04Pfu/qN6x3sBDwGdgB3Ap9y9LHrsM8B3o6f+j7s/erR7qSQRjPU79nHBz19nfN8OPHTdaY3+mj/Ze+S2yvhQG8bxuPvvS/jDm6t55VsT6dUxtwmjE2nejlaSCLQLrJmlA9OAjwFDgalmNrTeafcA/+vuI4A7gR9Gr+0A3A6MA8YCt5tZ+yDjlSO5Oy8v3cznHpmDGdx16bBAEgRAUYfWJ5UgAL5wZl8y0tL47WsrmygqEQm6umkssMLdVwGY2XRgMrAk5pyhwM3R968Az0XfXwi86O47ote+CEwCngg4ZgHeXrmNe19Yzty1O+nZoTXTrhlDYfvWYYd1VJ3bZXNVcSFPlaxn1da9AGRlpHHdR3pz7pAuIUcnkpqCThI9gPUx22VESgaxFgKXE6mSugxoa2YdG7m2R3ChCkQGyN37wjLeXrmdru2yufuyYVxdXERmemqMu7zpo/0p27mfqupaANZu38f1j5Zw+Zge3P6JUz7UJiIiR5cMDdffAn5tZtcBrwPlQG28F5vZDcANAD179gwivhZh/8FavvHkAp4v3URBmyy+94mhXDuu54e6mya7bnk5PPq5sYe3D9bU8euXP2Daqyt584NtjOnZcI3lhP4duXZcL9LSgqlOE0lVQSeJcqAoZrswuu8wd99ApCSBmbUBrnD3CjMrBybWu/bV+jdw9weAByDScN2EsbcYVdW13PBYCW+u2MY3zx/I9Wf2oXVWMvx+OHlZGWncfMEgLjilKz+Y+T6rt+390DlVNbU8X7qJvy7ayE+vHHFcjd5vfLCV7z23mP3Vcf+u+ZDiXh24/ZKhdG6bfXjf3LU7WLdjH5NH9lDiklAF2rvJzDKA5cC5RJLDHOAady+NOacA2OHudWZ2N1Dr7rdFG67nAmOip84DTj3URtEQ9W46fgdqavnPx+by2vKt/PTKkVx5amHYISWcu/P0vHK+/9dSamqdi0d2a7B6rXt+Dp+b0IecrEjpav66nVz7+3fplpfNadHBgMfrYG0df1u0kdysdO6+bDiDu7blx88vZVbpZgDG9+3AT68cSVGH5G4PktR2tN5NiegCexFwH5EusA+5+91mdidQ4u4zzOxKIj2anEh105fd/UD02s8B/x39qLvd/eGj3UtJomGlGyp5em45B2s//Gt32abdzFmzkx9dPpwpY1t2dd3Gyv3c9pdS5q/b2eDxbXsO0qcgl3uuGkleTgZX/fYd2uVk8ucvfuTwdCQnYsWW3dz81EIWlVWSZpCTmc4Xz+5HQdtW3P339wH43ieGcHVxUWC9y6RlCzVJJFJLSxLuznvllVRV13Fa7/Yf+gJ5f+Mu7ntpObNKN9MqI402rT5chZSRbnzt3IFcM65lJ4h4vL1iG7f8eREbK/fTLieTjLQ0nrnxI/TsePK/8mtq63jwjdVs2V3Flyb2P5x01u/Yx7f+tJB3V+/gvCGd+eHlI04qIYk0REmimdm+5wDPzCvnT3PXs3zzHgDOG9KF708+hR75OSzbtJtf/HM5M9/bRNtWGVx/Zh8+O6EPeTnq2XOydldV84OZ7/PK0q384bpiTumeF/g96+qch99ew4+fj0ys+IPLhjNpWNfA7ysth5JEM7FldxUPvLaKP767lqrqOkb3zOfKUwvZe6CGn7/4AWYwtk8HXlu+ldysDD47oTefP6Ovun02Ex9s3s03nlrA4vJd3DixH7dcMEiN2tIkNHdTM/DQm6v5yaylHKyp49JRPfjixH5HTGT3sWHduH1GKfPW7eRLE/vx+TP60v4kRzBLchnQpS3PfmkCd8wo5TevrmTllj38/JOjyG2gGlGkqagkkQJ27D3I+B/8k9P6tOd/Lh1OnwLNS9SSuTuPvr2GO/+2hH6d2jC8MFLllZWexqfG92JYj+CrwKR5UUkixf2pZD0Ha+u47ROnKEEIZsZ1E/rQuyCXH8x8n3+tjvQKr9xXzdPzyrj5/EHccFZf0lUVJU1ASSLJ1dU5j/9rHaf1bs+grlonQf5t4qDOTBzU+fD2zr0H+c5z7/Hj55fyyrIt/OzqkUk/35Ykv9SYkKcFe3PFNtZu38enxvcKOxRJcu1zs5h2zRjuvWokSzbs4mO/eIO/LCg/9oUiR6GSRJL74+y1dMzNUpdHiYuZccWphYzt04GvP7mAr01fwCtLt3D1aUUYkeqnId3axrVwlAgoSSSVyv3VfOJXbzCkaztuv+QU0gxeen8zN5zVj1YZqTXRnoSrqENrnrxhPPe/upJf/PMDnluw4fCxDrlZ/PiKEZw/9PimT6+rc0rW7mTfwRoAWmWkc1rv9mSkyAzBcmKUJJLIA6+vZP2O/WzdfYDz7n2N4YV5OHBNC58uQ05MRnoaXz13AJNHdWdDRRUQmczxJ7OW8YX/LeHacT255cJBZGVEvuRbZaQ32tjt7nz3L4t5/N11R+w/rXd77psymh75OcE+jIRGSSJJbN19gIfeXMPFI7vzX5MGcceMUl56fwtnD+zUJNM+SMvVq2PuETPbfqR/R+6ZtYwH31jN/8V86ffIz+Heq0cyvm/HD33Gr15ewePvruP6M/rw8RHdAFi+aTf/8/f3+dh9r/ODy4dz7uBIycSMlJtiXhqncRJJ4o4ZpTw2ey0v3Xw2fQpycXfmrNlJ746t6dwu+9gfIHKcStbsYO7ayGSGdQ5Plaxnzfa9fGliP75+3sDDM+FO/9c6bn3mPS4f04N7rxp5xBxha7fv5avTF7BwfcURn33hKV340eUj4hrQ+c7K7azZvperi4vUbTckmpYjyZXt3MdH73mNK07twQ8vHxF2ONJC7T1Qw51/XcKTJevplpd9eK6vD7bsYUL/Av7wmeIGp1Cvrq3j2Xnl7Nh3EIgM/nz4rdUUtGnFzz85qsGSCcDKrXv44cz3een9LQCc3rcj900ZRRf9KEo4JYkkd8ufFvKXhRt49VsT6a66XQnZ84s38pcFG6iLfjd0bpvNrR8bfFzTfywur+QrT8xn7fa9DOuR9+Epzt0p3bCL7Mx0vnROPzq0zuL7f11CTlY69141knMGd274gyUQShJJ7G+LNvDVJ+bz2Ql9+N4nhoYdjkiT2Xughp+9uJwVW/Y0eLxfpzZ86Zx+FLSJTH2+YssevvLEfJZv3s0r35yotrgEUpJIUtP/tY5vP/sep/XqwB+uK6ZttmZrlZZt864qzvjxy1w7rhd3XHJK2OG0GEdLEurgHJIHX1/Frc+8x9kDO/Ho58YqQYgAXdplc/HI7jxVsp7KfdVhhyMoSYTi2fll3D3zfT4+ohsPfLr48JrJIgKfP6Mv+w7W8n//Wht2KIKSRMKt3b6X7z67mNN6t+cXnxx1eCCTiEQM7d6OMwcU8MhbazhYUxd2OC2evqESqLq2jq9OX0BamnHflNGazkCkEZ8/sy9bdh9gxsINxz5ZAqUR1wl030vLWbi+gmnXjNE0BiJHcdaAAgZ1actvX1tJRnSAXXZmOh8d3Fml7wRTkkiQRWUV3P/qSj5ZXHR4WgMRaZiZ8cWJffnGkwv5+pMLDu8fVZTPr68ZrXUyEkhJIkGemVdOVnoa3/3EkLBDEUkJl47qwWm9O1BdG+mmv3B9Bd99bjEX/eIN7rlqJGcP6gSAYSpdBCjwJGFmk4BfAOnA7939R/WO9wQeBfKj59zq7jPNrDfwPrAseupsd/9i0PEGwd15oXQTZw3spK6uInEysyNKDH0KchlVlM+XH5/HDY/NPbw/zeB7nxjKZyf0CSPMZi/QJGFm6cA04HygDJhjZjPcfUnMad8FnnL335jZUGAm0Dt6bKW7jwoyxkR4r7ySDZVV3HzBoLBDEUlpvQtyefrGj/DnuWVU7o+Mo3jjg638cOZSzhxQQP/OWuK3qQVdRhsLrHD3Ve5+EJgOTK53jgPtou/zgGbXnWFW6SbS04zzhmg+GpGTlZ2ZzqfG9+LL5/Tny+f051dTx9C6VTq3/HkRtXXNZwaJZBF0kugBrI/ZLovui3UH8CkzKyNSivhKzLE+ZjbfzF4zszMbuoGZ3WBmJWZWsnXr1iYMvenMKt3MuD4dtGSkSAA6tW3FHRefwvx1FTz05uqww2l2kqG1ZyrwiLsXAhcBj5lZGrAR6Onuo4GbgcfNrF39i939AXcvdvfiTp06JTTweKzYsocVW/Zw4Slao1okKJNHdee8IZ2554VlvLNyuwbhNaGgk0Q5UBSzXRjdF+t64CkAd38HyAYK3P2Au2+P7p8LrAQGBhxvk5tVugmAC045vvWERSR+Zsbdlw0nJyudqQ/OZtjts5j86zd5Ifr/n5y4oJPEHGCAmfUxsyxgCjCj3jnrgHMBzGwIkSSx1cw6RRu+MbO+wABgVcDxNrkXSjcxsjCPbnkaPCcSpC7tsnnp5rOZds0YPjuhNxX7q/nvZxdzoKY27NBSWqBJwt1rgJuAWUS6sz7l7qVmdqeZXRI97ZvAF8xsIfAEcJ1H5i8/C1hkZguAPwNfdPcdQcbb1DZW7mdhWSUXqKpJJCEK2rTi4yO68e2LhnDX5GFs23OAme9tDDuslBb4OAl3n0mkQTp2320x75cAExq47mng6aDjC9Iz8yI1a2qPEEm8MwcU0K9TLg+/tYZLR/X48Op4EpdkaLhulrbuPsBvXl3JRwd3pn/nNmGHI9LimBnXfaQ3i8oqmb++IuxwUpaSREB+9uJyqqpr+c7HNQ2HSFguH1NI21YZPPLWmrBDSVlKEgFYsmEXT85Zx3+c3pt+nVSKEAlLbqsMriouYuZ7G9m8qyrscFKSJvhrYu7OXX9bQl5OJl87d0DY4Yi0eP9xei8efns1t/1lMaf2ag/A4K7tOGtg8o2rSkZKEk3sH4s38c6q7dw1+RTyWmsyP5Gw9S7I5ePDu/G3RRuZVboZgKyMNN799rm0z9UsCMei6qYmtHB9Bd/600KG98hj6tieYYcjIlG/mjqa0u9fSOn3L2TGTRM4WFPHUyXrj32hKEk0ldXb9vLZR+bQsU0Wf7iuWEuTiiQRMyO3VQa5rTIYUZjPuD4deGz2Wk0IGAd9kzWBLbur+I+H3gXg0c+OpXPb7JAjEpGj+cxHelO2cz+vLN0SdihJT0miCdwxo5Rtuw/y8HWn0Ve9mUSS3vlDu9C1XTaPvrMm7FCSnpLESarYd5AXl2zmmnE9GVmUH3Y4IhKHzPQ0rh3Xkzc+2MaqrXvCDiepKUmcpL8u2kh1rXP5mPrLZIhIMpsytieZ6cZjs9eGHUpSU5I4Sc/MK2NQl7YM7fahpS5EJIl1atuKi4Z346k561myYVfY4SQtJYmTsHrbXuavq+DyMZo8TCQV/b9Jg2mXk8mn//AuK7ao2qkhShIn4dl5ZaQZXDpaVU0iqahHfg7/9/lxmMGnfv8u63fsCzukpKMR1yeors55Zn45E/oX0KWduryKpKq+ndrw2PXjmPLAbC759ZuHFwjrkJvFT68a0eIXDFNJ4gSVrN1J2c79arAWaQaGdGvHH68fx+n9OtI9P4fu+TmUrN3BHTNKww4tdCpJnKBn5pXROitdCwqJNBPDC/O4/9pTD2/f/+oKfvL8Ml5eupmPDm65a9SrJHECdldVM2PhBj4+vButs5RnRZqjz5/Rl/6d23D7jFL2H2y562QrSZyAZ+eXs+9gLZ8+vVfYoYhIQLIy0rhr8jDW79jPtFdWhB1OaJQkjpO789g7axlZmMeIQo2wFmnOTu/XkctG9+B3r69kzba9YYcTCiWJ4/Tu6h18sGUP145XKUKkJfj2RYMxrMXO86QkcZwem72WvJxMLh7RPexQRCQBOrfN5sJhXXl6bhlV1S2vbSLwJGFmk8xsmZmtMLNbGzje08xeMbP5ZrbIzC6KOfbt6HXLzOzCoGM9li27qpi1eBNXnVpITlZ62OGISIJMHVvErqoaZr63MexQEi7QJGFm6cA04GPAUGCqmQ2td9p3gafcfTQwBbg/eu3Q6PYpwCTg/ujnhWb6nPXU1LmqmkRamNP7dqRvQS6Pv7su7FASLuiSxFhghbuvcveDwHRgcr1zHDg0O14esCH6fjIw3d0PuPtqYEX080JRW+dM/9c6zhxQQJ+C3LDCEJEQmBlTx/akZO1Olm/eHXY4CRV0kugBxC4kWxbdF+sO4FNmVgbMBL5yHNdiZjeYWYmZlWzdurWp4v6Qd1ZuZ0NlFVcXFwV2DxFJXlecWkhWelqLK00kQ8P1VOARdy8ELgIeM7O443L3B9y92N2LO3XqFFiQz8wro212BucPbbkjL0Vasg65WUwa1pVn5pW1qMF1QQ8XLgdif3oXRvfFup5ImwPu/o6ZZQMFcV6bEHsO1PCPxZu4dHQPsjPVYC3SUk0d25MZCzcw9PbnMSDNjNsvHsqnT+8ddmiBCbokMQcYYGZ9zCyLSEP0jHrnrAPOBTCzIUA2sDV63hQza2VmfYABwL8CjrdB/3hvI/ura7nyVE3mJ9KSje/bgbsmn8JN5/Tny+f0p2+nXB54YxV1dR52aIEJtCTh7jVmdhMwC0gHHnL3UjO7Eyhx9xnAN4EHzewbRBqxr3N3B0rN7ClgCVADfNndQynjPT2vjN4dWzOmZ/swbi8iScLMjig19O/chq9NX8A7q7YzoX9BeIEFKPDZ6dx9JpEG6dh9t8W8XwJMaOTau4G7Aw3wGNbv2MfsVTu4+fyBWn1ORI5w4SldycvJ5Il/rWu2SSIZGq6T2rPzI80gl2n1ORGpJzsznctG9+CF0s3s2Hsw7HACoSRxDM/OL2d83w4UdWgddigikoSmjC3iYG0dz8wrCzuUQChJHMX2PQdYvW0v57bgBUdE5OgGd23HqKJ8npyznkhzavOiJHEUyzZFRlYO6dbuGGeKSEs2dWwRH2zZw7x1O8MOpcnFnSTMLMfMBgUZTLJ5P5okBnVtG3IkIpLMPjGiO7lZ6Tz01pqwQ2lycSUJM7sYWAA8H90eZWb1xzs0O8s27aKgTRad2rYKOxQRSWK5rTK4/ow+/H3RRuas2RF2OE0q3pLEHUQm16sAcPcFQJ+AYkoaSzftZnBXVTWJyLF9cWI/urbL5vt/LaW2GQ2uizdJVLt7Zb19zedvoQG1dc7yzbtV1SQicWmdlcG3LxrM4vJd/Hnu+mNfkCLiTRKlZnYNkG5mA8zsV8DbAcYVurXb91JVXcdgJQkRidMlI7tT3Ks9P521jF1V1WGH0yTiTRJfIbL4zwHgcaAS+HpQQSWDpdFGa1U3iUi8zIzbLz6F7XsPMu2VFWGH0ySOmSSiq8H93d2/4+6nRV/fdfeqBMQXmqWbdpNmMKBLm7BDEZEUMrwwjwuGduG5+eXNYtzEMZNEdFK9OjPLS0A8SWPpxl30LsjV1OAictzOHdyFzbsOHK6RSGXxTvC3B3jPzF4E9h7a6e5fDSSqJLBs826GdW9ReVFEmsjZgyILoL26bGvKD8aNt03iGeB7wOvA3JhXs7T3QA1rt+9To7WInJAu7bIZ3LUtry3fEnYoJy2ukoS7PxpdNGhgdNcyd28eTfcNWLZZI61F5ORMHNSZ37+xit1V1bTNzgw7nBMW74jricAHwDTgfmC5mZ0VYFyh0pxNInKyJg7qRE2d8/bK7WGHclLirW66F7jA3c9297OAC4GfBxdWuJZu3EVuVjo98nPCDkVEUtSpvdrTplUGry7benhfdW0d2/YcCDGq4xdvw3Wmuy87tOHuy80sdctPx7B0U2SkdVqaVqITkROTmZ7GhP4deW3ZFtyd6lrn+kfn8MYH2yju1Z5LRnXnouHdKGiT3HPDxVuSKDGz35vZxOjrQaAkyMDC4u6ROZtU1SQiJ2nioM5sqKxi+eY9fPNPC3njg218sriIXVXV3PaXUs6551U2Vu4PO8yjirckcSPwZeBQl9c3iLRNNDvb9hykcn81AzprEJ2InJyzB0a6wt7wWAlrt+/jvyYN5saJ/QBYsL6Cq3/7Dve+sJx7rhoZZphHFW9JIgP4hbtf7u6XA78EmuUos0NZXe0RInKyuufnMLBLG9Zu38f1Z/Thi2f3PXxsVFE+103ozdPzynh/464Qozy6eJPEP4HYb80c4KWmDyd8Gyois410V5IQkSZw8/mD+MZ5A/nORUMwO7Kd88sT+9MuO5Mf/mNpSNEdW7xJItvd9xzaiL5vHc+FZjbJzJaZ2Qozu7WB4z83swXR13Izq4g5VhtzLCGLHB0qSXTLy07E7USkmZs0rCtfO29Agx1h8lpn8pWP9uf15Vt544OtDVwdvniTxF4zG3Now8xOBY7Z2hKdHHAa8DFgKDDVzIbGnuPu33D3Ue4+CvgVkdHdh+w/dMzdL4kz1pOyqbKKrIw0OuRmJeJ2ItLCffr0XhS2z+GHM5dSl4SLFcWbJL4O/MnM3jCzN4EngZviuG4ssMLdV7n7QWA6MPko508FnogzpkBsqKyiW172h4qFIiJBaJWRzlfPHcCSjbtYWFZx7AsSLN5pOeaY2WBgUHRXvNNy9ABil2gqA8Y1dKKZ9SKyJOrLMbuzzawEqAF+5O7PNXDdDcANAD179owjpKPbWLFfVU0iklBnDigAIj2eRvdsH3I0R4p3Wo6riLRLLAYuBZ6MrX5qIlOAP0enJj+kl7sXA9cA95lZv/oXufsD7l7s7sWdOnU66SA2VlbRPU+N1iKSON3ycujSrhUL1idfSSLe6qbvuftuMzsDOBf4A/CbOK4rB4pitguj+xoyhXpVTe5eHv1zFfAqMDrOeE9IbZ2zeVcV3fJVkhCRxBpVlM/CFE4Sh37dfxx40N3/DsTTsjsHGGBmfaKzyE4BPtRLKVqV1R54J2ZfezNrFX1fAEwAlsQZ7wnZtucANXVOV5UkRCTBRhW1Z832fezcezDsUI4Qb5IoN7PfAZ8EZka/vONZ1a6GSAP3LOB94Cl3LzWzO80strfSFGC6H7nW3xAi04EsBF4h0iYRaJLYUBHpsNVdbRIikmAjiyKLnC1IssbreKfluBqYBNzj7hVm1g245dBBM2vv7jsbutDdZwIz6+27rd72HQ1c9zYwPM74msTGyshAum4qSYhIgo0ozMcMFqyr4JxBncMO57B4ezftI2b8grtvBDbGnPJPoKkbshPuUJLorjYJEUmwNq0yGNi5bdJ1g423uulYmsWggo0V+8nOTCMvp9nOgi4iSexQ4/WRNe/haqokkTxPdBIOdX/VQDoRCcPIonx27qtm7fZ9YYdyWFMliWZhY+V+dX8VkdCMKsoHSKrxEqpuirGxsoqu7dRoLSLhGNilDTmZ6c0jSZhZ7Ko85zZBLKGqqa1j864qNVqLSGgy0tMY3iOveSQJYga2ufuOJoglVFt2H6DO1f1VRMI1qmc+Szbs4kBN7bFPToCjdoE1s5sbOwQ0q/U9D4+RUElCREI0qiifg7V1vL9x9+E2ijAdqyTxAyLTZbSt92oTx7UpRYsNiUgyGBlNDIuSZLzEsQbTzQOec/e59Q+Y2eeDCSkcGys02lpEwtc9L5uOuVksKqsMOxTg2KWBcmCtmX2tgWPFAcQTmg2V+8nNSqdddrwzlYiIND0zY0RhXtKUJI6VJIYSme31c9FZWTscegHxLDqUMjZVVtEtXwPpRCR8IwrzWbFlD3sP1IQdyjGrm35HZF6mvsBcjhwP4dH9zcKhZUtFRMI2siiPOofF5ZWM69sx1FiOWpJw91+6+xDgIXfv6+59Yl7NJkGAli0VkeQxvEek8fq98vDbJeLqoeTuNwYdSJiqa+vYuueAGq1FJCl0atuK7nnZLEyCxutm1Y31RG3eVYW7pggXkeQxojA/KRqvlSSAquo6RhTm0atjbtihiIgAMKIoj7Xb91G5L9w+QkoSQP/ObZhx0xmMD7mBSETkkJGF0UF15eGWJpQkRESS0LAekTWvwx5UpyQhIpKE8nIy6VOQy8KQZ3xh0VcAAA3VSURBVIRVkhARSVIjCvNC7warJCEikqRGFOazsbKKLburQotBSUJEJEmNKIy2S6wPrzQReJIws0lmtszMVpjZrQ0c/7mZLYi+lptZRcyxz5jZB9HXZ4KOVUQkmQzvkUdWehpz1oa3rlugU56aWTowDTgfKAPmmNkMd49d1e4bMed/BRgdfd8BuJ3IbLMOzI1euzPImEVEkkV2ZjqjivKZvSq8JBF0SWIssMLdV7n7QWA6MPko508Fnoi+vxB40d13RBPDi8CkQKMVEUky4/p2YHF5JburwhlUF3SS6AGsj9kui+77EDPrBfQBXj6ea83sBjMrMbOSrVu3NknQIiLJYnzfjtTWOSVrw6lESaaG6ynAn939uFb/dvcH3L3Y3Ys7deoUUGgiIuEY07M9menG7FXbQ7l/0EmiHCiK2S6M7mvIFP5d1XS814qINEs5WemMLMzn3ZDaJYJOEnOAAWbWx8yyiCSCGfVPMrPBQHvgnZjds4ALoivitQcuiO4TEWlRxvftyHvllewJYaW6QJOEu9cANxH5cn8feMrdS83sTjO7JObUKcB0d/eYa3cAdxFJNHOAO6P7RERalMPtEmsS/xUYaBdYAHefCcyst++2ett3NHLtQ8BDgQUnIpICxvTKJyPNmL1qBxMHdU7ovZOp4VpERBrQOiuDkUX5vLs68Y3XShIiIilgfN8OLCqrZG+C2yWUJEREUsC4PuGMl1CSEBFJAaf2ak9WehqvL0/soGElCRGRFJDbKoMJ/Tvy/OJNxHQEDZyShIhIivjYsG6UV+xncfmuhN1TSUJEJEWcP7QL6WnGPxZvTNg9lSRERFJE+9wsxvftkNAqJyUJEZEUMmlYN1Zt28sHW/Yk5H5KEiIiKeTCoV0wg3+8tykh91OSEBFJIZ3bZXNqz/YJa5dQkhARSTGThnVl6abdrNm2N/B7KUmIiKSYScO6AvB8afBVTkoSIiIpprB9a7q2y2ZFAhqvlSRERFJQfutMKvdXB34fJQkRkRSUl5NJ5T4lCRERaUB+60wq9h8M/D5KEiIiKSg/J0vVTSIi0rC81plUqLpJREQakpeTyYGaOqqqawO9j5KEiEgKym+dCRB4lZOShIhICsrPyQIIvMop8CRhZpPMbJmZrTCzWxs552ozW2JmpWb2eMz+WjNbEH3NCDpWEZFUkZcTKUlU7Au2h1NGkB9uZunANOB8oAyYY2Yz3H1JzDkDgG8DE9x9p5l1jvmI/e4+KsgYRURS0aHqpooUr24aC6xw91XufhCYDkyud84XgGnuvhPA3bcEHJOISMo7VJJI9TaJHsD6mO2y6L5YA4GBZvaWmc02s0kxx7LNrCS6/9KGbmBmN0TPKdm6dWvTRi8ikqTyDjVcB9wmEWh1U5wygAHARKAQeN3Mhrt7BdDL3cvNrC/wspm95+4rYy929weABwCKi4sTs56fiEjI2rbKID3NAh91HXRJohwoitkujO6LVQbMcPdqd18NLCeSNHD38uifq4BXgdEBxysikhLMLDJ/U4pXN80BBphZHzPLAqYA9XspPUekFIGZFRCpflplZu3NrFXM/gnAEkREBID8nOBHXQda3eTuNWZ2EzALSAcecvdSM7sTKHH3GdFjF5jZEqAWuMXdt5vZR4DfmVkdkWT2o9heUSIiLV27BJQkAm+TcPeZwMx6+26Lee/AzdFX7DlvA8ODjk9EJFXlt85kx97UbpMQEZGAJKK6SUlCRCRF5eVkBj7iWklCRCRF5bXOYveBGmrrguv9ryQhIpKi8nMycYfdVcFVOSlJiIikqH9P8qckISIi9SRikj8lCRGRFJWIhYeUJEREUlTe4YWHguvhpCQhIpKiEjFduJKEiEiKOpwk1HAtIiL1ZWWkkZuVroZrERFpWF7AU3MoSYiIpLC81llqkxARkYbl52RSGeDqdEoSIiIpTNVNIiLSqPzWwS48pCQhIpLC8lpnUrG/msj6bU1PSUJEJIXl52RxsKaOquq6QD5fSUJEJIUFPepaSUJEJIX9eybYYHo4KUmIiKSw/IDXlFCSEBFJYe1SPUmY2SQzW2ZmK8zs1kbOudrMlphZqZk9HrP/M2b2QfT1maBjFRFJNYeqm3YF1CaREcinRplZOjANOB8oA+aY2Qx3XxJzzgDg28AEd99pZp2j+zsAtwPFgANzo9fuDDJmEZFUkt86uqZEirZJjAVWuPsqdz8ITAcm1zvnC8C0Q1/+7r4luv9C4EV33xE99iIwKeB4RURSSm5WOulplrLVTT2A9THbZdF9sQYCA83sLTObbWaTjuNazOwGMysxs5KtW7c2YegiIsnPzKLzN6VmkohHBjAAmAhMBR40s/x4L3b3B9y92N2LO3XqFFCIIiLJ69Co6yAE2iYBlANFMduF0X2xyoB33b0aWG1my4kkjXIiiSP22lcDi1REJEWdN6QLHXOzAvnsoJPEHGCAmfUh8qU/Bbim3jnPESlBPGxmBUSqn1YBK4EfmFn76HkXEGngFhGRGP990ZDAPjvQJOHuNWZ2EzALSAcecvdSM7sTKHH3GdFjF5jZEqAWuMXdtwOY2V1EEg3Ane6+I8h4RUTkSBbUzIFhKC4u9pKSkrDDEBFJKWY2192LGzqWDA3XIiKSpJQkRESkUUoSIiLSKCUJERFplJKEiIg0SklCREQa1ay6wJrZVmDtcVxSAGwLKJxk11KfXc/dsui549PL3Ruc16hZJYnjZWYljfUNbu5a6rPruVsWPffJU3WTiIg0SklCREQa1dKTxANhBxCilvrseu6WRc99klp0m4SIiBxdSy9JiIjIUShJiIhIo1pEkjCzSWa2zMxWmNmtDRxvZWZPRo+/a2a9Ex9l04vjuW82syVmtsjM/mlmvcKIs6kd67ljzrvCzNzMmk0XyXie3cyujv67l5rZ44mOMQhx/Lfe08xeMbP50f/eLwojzqZkZg+Z2RYzW9zIcTOzX0b/ThaZ2ZgTupG7N+sXkcWOVgJ9gSxgITC03jlfAn4bfT8FeDLsuBP03OcAraPvb2wpzx09ry3wOjAbKA477gT+mw8A5gPto9udw447Qc/9AHBj9P1QYE3YcTfBc58FjAEWN3L8IuAfgAHjiSwTfdz3aQklibHACndf5e4HgenA5HrnTAYejb7/M3CumVkCYwzCMZ/b3V9x933RzdlE1hFPdfH8ewPcBfwYqEpkcAGL59m/AExz950A7r4lwTEGIZ7ndqBd9H0esCGB8QXC3V8HjrZa52Tgfz1iNpBvZt2O9z4tIUn0ANbHbJdF9zV4jrvXAJVAx4REF5x4njvW9UR+daS6Yz53tNhd5O5/T2RgCRDPv/lAYKCZvWVms81sUsKiC048z30H8CkzKwNmAl9JTGihOt7vgAYFusa1pAYz+xRQDJwddixBM7M04GfAdSGHEpYMIlVOE4mUHF83s+HuXhFqVMGbCjzi7vea2enAY2Y2zN3rwg4s2bWEkkQ5UBSzXRjd1+A5ZpZBpDi6PSHRBSee58bMzgO+A1zi7gcSFFuQjvXcbYFhwKtmtoZIXe2MZtJ4Hc+/eRkww92r3X01sJxI0khl8Tz39cBTAO7+DpBNZBK85iyu74BjaQlJYg4wwMz6mFkWkYbpGfXOmQF8Jvr+SuBlj7b8pLBjPreZjQZ+RyRBNIe6aTjGc7t7pbsXuHtvd+9NpC3mEncvCSfcJhXPf+vPESlFYGYFRKqfViUyyADE89zrgHMBzGwIkSSxNaFRJt4M4D+ivZzGA5XuvvF4P6TZVze5e42Z3QTMItIL4iF3LzWzO4ESd58B/IFI8XMFkYagKeFF3DTifO6fAm2AP0Xb6de5+yWhBd0E4nzuZinOZ58FXGBmS4Ba4BZ3T+lSc5zP/U3gQTP7BpFG7OtS/YegmT1BJOEXRNtabgcyAdz9t0TaXi4CVgD7gM+e0H1S/O9JREQC1BKqm0RE5AQpSYiISKOUJEREpFFKEiIi0iglCRERaZSShAhgZh3NbEH0tcnMyqPvK6LdRZv6fneY2beO85o9jex/xMyubJrIRI6kJCECuPt2dx/l7qOA3wI/j74fBRxz6oboSH2RZkdJQuTY0s3swej6Cy+YWQ6Amb1qZveZWQnwNTM71cxeM7O5Zjbr0IybZvbVmHU7psd87tDoZ6wys68e2mmRdT4WR19frx9MdATtr6PrJ7wEdA74+aUF068fkWMbAEx19y+Y2VPAFcAfo8ey3L3YzDKB14DJ7r7VzD4J3A18DrgV6OPuB8wsP+ZzBxNZ06MtsMzMfgOMIDIydhyRdQDeNbPX3H1+zHWXAYOIrIvQBVgCPBTIk0uLpyQhcmyr3X1B9P1coHfMsSejfw4iMnHgi9EpTtKBQ/PkLAL+z8yeIzJ30iF/j06qeMDMthD5wj8DeNbd9wKY2TPAmUQWCjrkLOAJd68FNpjZy03ylCINUJIQObbY2XFrgZyY7b3RPw0odffTG7j+40S+2C8GvmNmwxv5XP3/KElHbRIiTWMZ0Cm6VgFmlmlmp0TXryhy91eA/yIyDX2bo3zOG8ClZtbazHKJVC29Ue+c14FPmll6tN3jnKZ+GJFD9MtFpAm4+8FoN9Rfmlkekf+37iOyXsMfo/sM+KW7VzS2Oq67zzOzR4B/RXf9vl57BMCzwEeJtEWsA95p6ucROUSzwIqISKNU3SQiIo1SkhARkUYpSYiISKOUJEREpFFKEiIi0iglCRERaZSShIiINOr/A1ovhqGJZpEAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvo20EjjIDYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a9b109c-9089-41b6-b0b3-747bb008b82f"
      },
      "source": [
        "# output submission\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "preds = model.predict(vector_test)\n",
        "\n",
        "if not threshold:\n",
        "    threshold = 0.3\n",
        "preds = (preds >= threshold).astype(int)\n",
        "sub.target = preds\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "\n",
        "labels = pd.read_csv('labels.csv').target\n",
        "print(\"The submission f1_score is: \", f1_score(labels, preds, average='weighted'))\n",
        "# !curl -X PUT --upload-file submission.csv ali.140714.xyz:8000/tweets.csv \n",
        "# submission result\n",
        "# GRU 64, max_features = 10000, embed_size=128, max_len=150, no embed, f1_score 0.75460\n",
        "# GRU 64, max_features = 10000, embed_size=128, max_len=150, no embed, train_size 0.9 (default 0.8), f1_score 0.81083\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The submission f1_score is:  0.7818268904232742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlFzsb2GLEJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}