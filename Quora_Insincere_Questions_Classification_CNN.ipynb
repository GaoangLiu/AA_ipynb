{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora Insincere Questions Classification. ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUjHJFLlpSGBbs7XyHSRoO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaoangLiu/ipynb/blob/master/CNN_Quora_Insincere_Questions_Classification_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzJMWmNBzkXn",
        "colab_type": "text"
      },
      "source": [
        "[Quora insincere quetions classificaiton - Kaggle](https://www.kaggle.com/c/quora-insincere-questions-classification/data)\n",
        "\n",
        "## Problem Description \n",
        " \n",
        "In this competition you will be predicting whether a question asked on Quora is sincere or not.\n",
        "\n",
        "An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
        "\n",
        "* Has a non-neutral tone\n",
        "  * Has an exaggerated tone to underscore a point about a group of people\n",
        "  * Is rhetorical and meant to imply a statement about a group of people\n",
        "* Is disparaging or inflammatory\n",
        "  * Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
        "  * Makes disparaging attacks/insults against a specific person or group of people\n",
        "  * Based on an outlandish premise about a group of people\n",
        "  * Disparages against a characteristic that is not fixable and not measurable\n",
        "\n",
        "* Isn't grounded in reality\n",
        "  * Based on false information, or contains absurd assumptions\n",
        "* Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers\n",
        "\n",
        "The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect.\n",
        "\n",
        "Note that the distribution of questions in the dataset should not be taken to be representative of the distribution of questions asked on Quora. This is, in part, because of the combination of sampling procedures and sanitization measures that have been applied to the final dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlFXmmI1zgaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get data from personal server\n",
        "! wget -O quora.zip ali.140714.xyz:8000/quora.zip \n",
        "! unzip quora.zip \n",
        "! ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sDKHmg10wKb",
        "colab_type": "text"
      },
      "source": [
        "## Explore\n",
        "Now let's play with the data !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmsSOmk09iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import re\n",
        "import os\n",
        "import timeit\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import logging\n",
        "logging.basicConfig(format='[%(asctime)s %(levelname)-8s] %(message)s', level=logging.INFO, datefmt='%m-%d %H:%M:%S')\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Embedding, Dropout, LSTM, GRU, Bidirectional\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import gensim.downloader as api"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vom-1Wv1PrM",
        "colab_type": "code",
        "outputId": "6e2486d8-e0b1-44c4-8993-e4380cc4428a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "train.target.value_counts()\n",
        "train.question_text.str.len().describe()\n",
        "\n",
        "# for i in range(1, 100):\n",
        "#   text_len = i * 10\n",
        "#   print(f\"Textlen upbound {text_len}\")\n",
        "#   vc = train[(train.question_text.str.len() <= text_len) & (train.question_text.str.len() >= text_len - 10)].target.value_counts()\n",
        "#   print(f\"Sincere {vc.get(0, 0)}, insincere {vc.get(1, 0)}, insincere ratio {vc.get(1, 0) / (vc.get(0, 0) + vc.get(1, 0.001))}\")\n",
        "\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>Who are entrepreneurs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>Is education really making good people nowadays?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>ffff7fa746bd6d6197a9</td>\n",
              "      <td>How many countries listed in gold import in in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>ffffa1be31c43046ab6b</td>\n",
              "      <td>Is there an alternative to dresses on formal p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>ffffae173b6ca6bfa563</td>\n",
              "      <td>Where I can find best friendship quotes in Tel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>ffffb1f7f1a008620287</td>\n",
              "      <td>What are the causes of refraction of light?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>fffff85473f4699474b0</td>\n",
              "      <td>Climate change is a worrying topic. How much t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375806 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid                                      question_text\n",
              "0       0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1       00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2       00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
              "3       000086e4b7e1c7146103                             Who are entrepreneurs?\n",
              "4       0000c4c3fbe8785a3090   Is education really making good people nowadays?\n",
              "...                      ...                                                ...\n",
              "375801  ffff7fa746bd6d6197a9  How many countries listed in gold import in in...\n",
              "375802  ffffa1be31c43046ab6b  Is there an alternative to dresses on formal p...\n",
              "375803  ffffae173b6ca6bfa563  Where I can find best friendship quotes in Tel...\n",
              "375804  ffffb1f7f1a008620287        What are the causes of refraction of light?\n",
              "375805  fffff85473f4699474b0  Climate change is a worrying topic. How much t...\n",
              "\n",
              "[375806 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJRz0x6Hqkb",
        "colab_type": "code",
        "outputId": "6c429a5c-e7af-49ba-83a6-586ba31cb553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>ffff7fa746bd6d6197a9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>ffffa1be31c43046ab6b</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>ffffae173b6ca6bfa563</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>ffffb1f7f1a008620287</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>fffff85473f4699474b0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>375806 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid  prediction\n",
              "0       0000163e3ea7c7a74cd7           0\n",
              "1       00002bd4fb5d505b9161           0\n",
              "2       00007756b4a147d2b0b3           0\n",
              "3       000086e4b7e1c7146103           0\n",
              "4       0000c4c3fbe8785a3090           0\n",
              "...                      ...         ...\n",
              "375801  ffff7fa746bd6d6197a9           0\n",
              "375802  ffffa1be31c43046ab6b           0\n",
              "375803  ffffae173b6ca6bfa563           0\n",
              "375804  ffffb1f7f1a008620287           0\n",
              "375805  fffff85473f4699474b0           0\n",
              "\n",
              "[375806 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L74YSwzK9Fty",
        "colab_type": "text"
      },
      "source": [
        "## Findings\n",
        "* The target value counts: `sincere 1225312, insincere 80810, ration 15:1`. Thus insincere is relatively rare in the questions \n",
        "* There are no empty questions, which is understandable, you're not asking a question until you say something. \n",
        "* `question_text`, \n",
        "  * mean length 70\n",
        "  * std 30\n",
        "  * min length 1 \n",
        "  * max length 1017\n",
        "* When the length of question text is above 10 and below 320, **the longer the length, the less sincere the question is**; for questions with length less than 10, 64.8% are insincere. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DANdmF7oDow7",
        "colab_type": "text"
      },
      "source": [
        "Try CNN first. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cGBRnDH9Sti",
        "colab_type": "code",
        "outputId": "aca847e3-bc53-48a2-ae27-cc7354851179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "class DeepLearning():\n",
        "  \"\"\" A template for running CNN models\"\"\"\n",
        "  def __init__(self, max_features=100000, max_sentence_len=200, embedding_dim=100):\n",
        "    self.max_features = max_features\n",
        "    self.max_sentence_len = max_sentence_len\n",
        "    self.embedding_dim = embedding_dim # For using embedded vector\n",
        "    self.filepath=\"weights_base.best.hdf5\" # saving the best model weights \n",
        "\n",
        "  def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
        "      \"\"\" A task-dependent method that will load data and do simple preprocessing,\n",
        "      @return: train_data, test_data, train_labels, test_labels\n",
        "      Load data and  \"\"\"\n",
        "      train = pd.read_csv(train_file, engine='python',\\\n",
        "          encoding='utf-8', error_bad_lines=False)\n",
        "      test = pd.read_csv(test_file, engine='python', \\\n",
        "          encoding='utf-8', error_bad_lines=False)\n",
        "      logging.info('CSV data loaded')\n",
        "      return train, test\n",
        "\n",
        "  def exploring_data(self, train):\n",
        "      '''Find patterns, informations'''\n",
        "      pass \n",
        "\n",
        "  def tokenize_text(self, text_train, text_test):\n",
        "      '''@para: max_features, the most commenly used words in data set\n",
        "      @input are vector of text\n",
        "      '''\n",
        "      tokenizer = Tokenizer(num_words=self.max_features)\n",
        "      text = pd.concat([text_train, text_test])\n",
        "      tokenizer.fit_on_texts(text)\n",
        "\n",
        "      sequence_train = tokenizer.texts_to_sequences(text_train)\n",
        "      tokenized_train = pad_sequences(sequence_train, maxlen=self.max_sentence_len)\n",
        "      logging.info('Train text tokeninzed')\n",
        "\n",
        "      sequence_test = tokenizer.texts_to_sequences(text_test)\n",
        "      tokenized_test = pad_sequences(sequence_test, maxlen=self.max_sentence_len)\n",
        "      logging.info('Test text tokeninzed')\n",
        "      return tokenized_train, tokenized_test, tokenizer\n",
        "      \n",
        "\n",
        "  def embed_glove_vector(self, word_index, model='glove-wiki-gigaword-100'):\n",
        "      glove = api.load(model) # default: wikipedia 6B tokens, uncased\n",
        "      zeros = [0] * self.embedding_dim\n",
        "      matrix = np.zeros((self.max_features, self.embedding_dim))\n",
        "      \n",
        "      for word, i in word_index.items(): \n",
        "          if i >= self.max_features or word not in glove: continue # matrix[0] is zeros, that's also why >= is here\n",
        "          matrix[i] = glove[word]\n",
        "\n",
        "      logging.info('Glove embedding vector created')\n",
        "      return matrix\n",
        "\n",
        "\n",
        "  def tfidf_vectorized(self, text_train, text_test):\n",
        "      \"\"\" Tokenize text with TfidfVectorizer()\n",
        "          Parameters such as ngram_range, max_features requires fine-tuning \n",
        "          @input: text Series, not DataFrame\n",
        "      \"\"\"\n",
        "      tv = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', \\\n",
        "                          analyzer='word', token_pattern=r'\\w{1,}',  stop_words='english', \\\n",
        "                          ngram_range=(1, 1), max_features=self.max_features)\n",
        "      # features_train = tv.fit_transform(train.comment_text)\n",
        "      # return features_train, 0\n",
        "      return (tv.fit_transform(text) for text in (text_train, test_train))\n",
        "\n",
        "\n",
        "  def build_model(self, embedding_matrix=np.zeros(0)):\n",
        "      dropout = 0.5\n",
        "      model = Sequential()\n",
        "      model.add(Embedding(self.max_features, self.embedding_dim, input_length=self.max_sentence_len))\n",
        "      model.add(Flatten())\n",
        "\n",
        "      model.add(Dense(64, activation='relu'))\n",
        "      model.add(Dropout(dropout))\n",
        "      model.add(Dense(64, activation='relu'))\n",
        "      model.add(Dropout(dropout))\n",
        "      \n",
        "      model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "      if embedding_matrix.size > 0:\n",
        "          model.layers[0].set_weights([embedding_matrix])\n",
        "          model.layers[0].trainable = False\n",
        "      logging.info(f'Model created')\n",
        "      return model\n",
        "\n",
        "  def run(self, model, x_train, y_train):\n",
        "      checkpoint = ModelCheckpoint(self.filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "      early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
        "\n",
        "      model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "      X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state=23)\n",
        "      history = model.fit(X_tra, y_tra, epochs=3, batch_size=128, validation_data=(X_val, y_val), \\\n",
        "                          callbacks=[checkpoint, early], verbose=1)\n",
        "      return model, history\n",
        "\n",
        "  def display_history(self, history):\n",
        "      acc = history['acc']\n",
        "      val_acc = history.history['val_acc']\n",
        "      loss = history.history['loss']\n",
        "    \n",
        "  def predict(self, y_test, labels, sub_file=\"sample_submission.csv\"):\n",
        "      res = pd.read_csv(sub_file)\n",
        "      res[labels] = y_test\n",
        "      res.to_csv('submission.csv', index=False)\n",
        "      logging.info(f\"Predictions were written to submission.csv\")\n",
        "\n",
        "  def describe_model(self, **dm):\n",
        "    for k, v in dm.items():\n",
        "      print(f\"{k}: {v}\")\n",
        "\n",
        "\n",
        "def save_predict(preds=[]):\n",
        "  train['text_len'] = 10 + 10 * ((train.question_text.str.len() - 1) // 10)\n",
        "  vc = train.groupby('text_len').target.value_counts()\n",
        "\n",
        "  test['preds'] = preds\n",
        "  test['text_len'] = 10 + 10 * ((test.question_text.str.len() - 1) // 10)\n",
        "  max_preds = test.groupby('text_len').preds.max()\n",
        "  min_preds = test.groupby('text_len').preds.min()\n",
        "\n",
        "  def classify_pred(row): # to either 0 or 1\n",
        "    tlen = row.text_len\n",
        "    vmin, vmax = min_preds[tlen], max_preds[tlen]\n",
        "    c0, c1 = vc.get((tlen, 0), 0.01), vc.get((tlen, 1), 0.01)\n",
        "    r = c0 / (c0 + c1)\n",
        "    return 1 if (row['preds'] - vmin) / (vmax - vmin) >= r else 0\n",
        "  \n",
        "  res = pd.read_csv('sample_submission.csv')\n",
        "  res['prediction'] = test.apply(classify_pred, axis=1)\n",
        "  res.to_csv('submission.csv', index=False)\n",
        "  logging.info('Predictions were made through external method.')\n",
        "\n",
        "  return res\n",
        "\n",
        "def save_predict_v2(y_preds):\n",
        "  bad, good = 80810, 1225312\n",
        "  preds = sorted([e[0] for e in y_preds])\n",
        "  idx_delta = int(len(preds) * (good / (good + bad)))\n",
        "  delta = preds[idx_delta]\n",
        "\n",
        "  res = pd.read_csv('sample_submission.csv')\n",
        "  res['prediction'] = [1 if p >= delta else 0 for p in y_preds]\n",
        "  res.to_csv('submission.csv', index=False)\n",
        "  logging.info('Predictions were made through external method v2.')\n",
        "\n",
        "  return res\n",
        "  \n",
        "\n",
        "# y_pred\n",
        "time_start = timeit.default_timer()\n",
        "dl = DeepLearning(max_features=200000, max_sentence_len=350, embedding_dim=300)\n",
        "train, test = dl.load_data()\n",
        "columns = ['target']\n",
        "labels = train[columns].values\n",
        "\n",
        "X_train, X_test, tokenizer = dl.tokenize_text(train[\"question_text\"].fillna(\"_na_\"), test[\"question_text\"].fillna(\"_na_\"))\n",
        "# embedding_matrix = dl.embed_glove_vector(tokenizer.word_index, 'word2vec-google-news-300')\n",
        "\n",
        "model = dl.build_model()\n",
        "model, history = dl.run(model, X_train[:10000], labels[:10000])\n",
        "model.load_weights(dl.filepath)\n",
        "y_preds = model.predict(X_test, batch_size=1024, verbose=1)\n",
        "final_preds = save_predict_v2(y_preds)\n",
        "\n",
        "time_stop = timeit.default_timer()\n",
        "print(f'Program run for {time_stop - time_start} seconds')\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[05-07 08:36:40 INFO    ] Model created\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/3\n",
            "9000/9000 [==============================] - 3s 338us/step - loss: 0.3480 - acc: 0.9020 - val_loss: 0.2621 - val_acc: 0.9300\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.93000, saving model to weights_base.best.hdf5\n",
            "Epoch 2/3\n",
            "9000/9000 [==============================] - 3s 323us/step - loss: 0.2135 - acc: 0.9359 - val_loss: 0.1978 - val_acc: 0.9300\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.93000\n",
            "Epoch 3/3\n",
            "9000/9000 [==============================] - 3s 319us/step - loss: 0.1542 - acc: 0.9390 - val_loss: 0.2084 - val_acc: 0.9300\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.93000\n",
            "375806/375806 [==============================] - 3s 9us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[05-07 08:36:56 INFO    ] Predictions were made through external method v2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Program run for 16.149937967002188 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viOkPI1pKXrm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d12ddc8a-2163-491e-a46c-b9787a795d39"
      },
      "source": [
        "sub = pd.read_csv('submission.csv')\n",
        "bad, good = 80810, 1225312\n",
        "# max_prob = max(sub.prediction)\n",
        "# print(max_prob)\n",
        "sub.prediction.value_counts()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    352554\n",
              "1     23252\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFXPmyWPH5Lt",
        "colab_type": "code",
        "outputId": "35964094-ddda-4323-b586-bfe3f546311e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "# ! mv submission.csv quora.csv\n",
        "# ! curl -X PUT --upload-file quora.csv ali.140714.xyz:8000\n",
        "# ! head submission.csv\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6320300698280334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f277ef44198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}